{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f5ae8316-1176-4993-bef6-d1017b63721e",
   "metadata": {},
   "source": [
    "# Week 4\n",
    "\n",
    "## Dataset Selection\n",
    "\n",
    "I chose the **Adult** dataset from UCI since it contains a good mix of categorical and continuous features. I'm downloading from an alternate site for two reasons.\n",
    "\n",
    "1. The UCI site has an invalid certificate at this time.\n",
    "2. The alternate site provides the CSV file directly instead of a Zip file.\n",
    "\n",
    "The format of the CSV file from the alternate site is slightly different from that from UCI but the data are identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee735e80-aaca-4c32-8474-11d431df75b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "#url = 'https://archive.ics.uci.edu/static/public/2/adult.zip'\n",
    "url = 'https://huggingface.co/datasets/scikit-learn/adult-census-income/resolve/main/adult.csv'\n",
    "file_name = os.path.basename(url)\n",
    "urlretrieve(url, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f37948-2fd1-4738-97f7-12b64482ee8e",
   "metadata": {},
   "source": [
    "## Data Cleaning & Preprocessing\n",
    "\n",
    "I handle missing values by imputing categorical values with the most frequent value and imputing continuous values by using the median value. I use one-hot encoding for the categorical values since there aren't very many of them. I use the standard scaler for the continuous values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ab52e1-2cda-496b-a613-ca000c41e3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(file_name)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(\"income\", axis=1)\n",
    "y = df[\"income\"]\n",
    "\n",
    "# Identify categorical and continuous features\n",
    "categorical_features = [\"workclass\",\"education\",\"marital.status\",\"occupation\",\n",
    "                        \"relationship\",\"race\",\"sex\",\"native.country\"]\n",
    "continuous_features = [\"age\",\"fnlwgt\",\"education.num\",\"capital.gain\",\n",
    "                       \"capital.loss\",\"hours.per.week\"]\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "# Preprocessing for continuous data\n",
    "continuous_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# Combine preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"categorical\", categorical_transformer, categorical_features),\n",
    "        (\"continuous\", continuous_transformer, continuous_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Build full pipeline with a model\n",
    "clf = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model accuracy:\", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4713c67-6e1e-4776-a60b-a213895d2697",
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import TargetEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Target encoding only for native-country\n",
    "categorical_features = [\"workclass\",\"education\",\"marital.status\",\"occupation\",\n",
    "                        \"relationship\",\"race\",\"sex\"]\n",
    "high_cardinality_feature = [\"native.country\"]\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "target_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"target_encoder\", TargetEncoder())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"categorical\", categorical_transformer, categorical_features),\n",
    "        (\"target\", target_transformer, high_cardinality_feature),\n",
    "        (\"continuous\", continuous_transformer, continuous_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "clf = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model accuracy:\", clf.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
