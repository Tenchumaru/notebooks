{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "import collections\n",
    "import cv2\n",
    "import itertools as it\n",
    "import numpy as np\n",
    "import operator as op\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "def ilen(iterable) -> int:\n",
    "    counter = it.count()\n",
    "    collections.deque(zip(iterable, counter), maxlen=0)\n",
    "    return next(counter)\n",
    "\n",
    "def show_and_wait(image):\n",
    "    cv2.imshow('tesst', image)\n",
    "    cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12  '-abcdefghijklmnopqrstuvwxyz 29\n"
     ]
    }
   ],
   "source": [
    "file_titles = [\n",
    "    'Ancient Apparition',\n",
    "    'Anti-Mage',\n",
    "    'Broodmother',\n",
    "    'Centaur Warrunner',\n",
    "    'Clinkz',\n",
    "    'Io',\n",
    "    'Juggernaut',\n",
    "    'Keeper of the Light',\n",
    "    \"Nature's Prophet\",\n",
    "    'Nyx Assassin',\n",
    "    'Outworld Devourer',\n",
    "    'Queen of Pain',\n",
    "]\n",
    "s = {c.lower() for c, _ in it.groupby(sorted(it.chain.from_iterable(file_titles)))}\n",
    "print(len(file_titles), ''.join(sorted(s)), len(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a process for determining the letters in the images.\n",
    "\n",
    "1. Create a mean image for each hero.  A mean image is the mean of all available images for a hero.\n",
    "1. Find the vertical extents of the text in the images.  This is not the vertical extents of the letters.  Adjust for the \"Q\" descender in \"Queen of Pain\".\n",
    "1. Crop the images to those vertical extents for the rest of the process.\n",
    "1. Find the horizontal extents of the text in the images.  This is not the horizontal extents of the letters.  This is the left edge of the left-most letter and the right edge of the right-most letter.\n",
    "1. Crop the images to those horizontal extents for the rest of the process.\n",
    "1. Find the horizontal extents of the letters.  Note that there are three instances of letters having overlapping bright pixels due to kerning:  \"TA\" and \"WA\" in \"CENTAUR WARRUNNER\" and \"AT\" in \"NATURE'S PROPHET\".\n",
    "1. Extract the letter images for each Hero using the uncropped mean images.\n",
    "1. Create a mask for each letter.\n",
    "1. Save a dictionary of letters to 2-tuples of the tuple of letter images and the tuple of masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0607089, 0.30146945, 0.99009055, dtype('float32'), (16, 120)),\n",
       " (0.06445182, 0.30316025, 0.98991597, dtype('float32'), (16, 120)),\n",
       " (0.04990751, 0.30292377, 0.98373413, dtype('float32'), (16, 120)),\n",
       " (0.055525534, 0.29388064, 0.98892814, dtype('float32'), (16, 120)),\n",
       " (0.07709418, 0.29646266, 0.987991, dtype('float32'), (16, 120)),\n",
       " (0.06797386, 0.24183136, 0.9715106, dtype('float32'), (16, 120)),\n",
       " (0.047699343, 0.29340824, 0.9785882, dtype('float32'), (16, 120)),\n",
       " (0.06739689, 0.32595894, 0.9854226, dtype('float32'), (16, 120)),\n",
       " (0.061220814, 0.30799037, 0.9865447, dtype('float32'), (16, 120)),\n",
       " (0.05696732, 0.30735385, 0.97635293, dtype('float32'), (16, 120)),\n",
       " (0.039441675, 0.29897118, 0.98545694, dtype('float32'), (16, 120)),\n",
       " (0.058194987, 0.30815405, 0.98471, dtype('float32'), (16, 120))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a mean image for each hero.  A mean image is the mean of all available images for a hero.\n",
    "directory_path = r'F:\\Dota 2\\Heroes\\Pictures'\n",
    "def fn(file_title):\n",
    "    def fn(file_name: str):\n",
    "        # Read the image.\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        image = cv2.imread(file_path)\n",
    "\n",
    "        # Color data adds no value to this methodology.\n",
    "        # Take the color channel with the lowest value.  This changes\n",
    "        # the shape of the image from (60, 160, 3) to (60, 160).\n",
    "        return image[:, :, np.argmin(np.sum(image.astype(np.float32), axis=(0, 1)))]\n",
    "\n",
    "    # Read and grey all files in the Pictures directory for the given file title.\n",
    "    _, _, file_names = next(os.walk(directory_path))\n",
    "    g = (file_name for file_name in file_names if file_name.startswith(file_title))\n",
    "    images = list(map(fn, g))\n",
    "\n",
    "    # Combine the list of two-dimensional tensors into a single three-dimensional tensor.\n",
    "    images = np.stack(images, axis=0)\n",
    "\n",
    "    # Compute the mean image.\n",
    "    mean = np.mean(images.astype(np.float32), axis=0) / 255\n",
    "\n",
    "    # Clean up the bottom edge.\n",
    "    mean[-1, :] = (mean[-2, :] + mean[0, :]) / 2\n",
    "    return mean\n",
    "    mean = fn(images)\n",
    "    return masking_factor, mean\n",
    "hero_mean_images = {s: fn(s) for s in file_titles}\n",
    "\n",
    "# Show the hero mean images.\n",
    "show_and_wait(np.vstack([i for i in hero_mean_images.values()]))\n",
    "cv2.destroyAllWindows()\n",
    "[(v.min(), v.mean(), v.max(), v.dtype, v.shape) for v in hero_mean_images.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Ancient Apparition': (6, 14), 'Anti-Mage': (5, 14), 'Broodmother': (5, 14), 'Centaur Warrunner': (6, 14), 'Clinkz': (5, 14), 'Io': (5, 14), 'Juggernaut': (5, 14), 'Keeper of the Light': (6, 14), \"Nature's Prophet\": (5, 14), 'Nyx Assassin': (5, 14), 'Outworld Devourer': (6, 14), 'Queen of Pain': (5, 14)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Ancient Apparition': (6, 14, ''),\n",
       " 'Anti-Mage': (21, 30, ''),\n",
       " 'Broodmother': (37, 46, ''),\n",
       " 'Centaur Warrunner': (54, 62, ''),\n",
       " 'Clinkz': (69, 78, ''),\n",
       " 'Io': (85, 94, ''),\n",
       " 'Juggernaut': (101, 110, ''),\n",
       " 'Keeper of the Light': (118, 126, ''),\n",
       " \"Nature's Prophet\": (133, 142, ''),\n",
       " 'Nyx Assassin': (149, 158, ''),\n",
       " 'Outworld Devourer': (166, 174, ''),\n",
       " 'Queen of Pain': (181, 190, '')}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the vertical extents of the text in the images.  This is not the vertical extents of the\n",
    "# letters.  Adjust for the \"Q\" descender in \"Queen of Pain\".\n",
    "\n",
    "# Find the maximum value of each row of each hero mean image.\n",
    "d = {s: np.max(hero_mean_images[s], axis=1) for s in file_titles}\n",
    "\n",
    "# Those that fall below the mean for the column are not in a letter.  These are the vertical\n",
    "# extents.  I need these for the mean image since it's not black outside of the letters.\n",
    "d = {k: v < np.mean(v) for k, v in d.items()}\n",
    "d = {k: [i + 1 for i, b in enumerate(v[:-1] ^ v[1:]) if b] for k, v in d.items()}\n",
    "\n",
    "# Adjust the vertical extents to account for the dark borders around the letters.  I want to\n",
    "# include those as part of the letters.  The \"Q\" of \"Queen of Pain\" needs special handling because\n",
    "# it has a descender.  For now, I'll adjust as if to ignore the \"Q\".\n",
    "d = {k: (a - 1, b + (1 if k == 'Queen of Pain' else 2)) for k, (a, b) in d.items()}\n",
    "hero_vertical_extents = d\n",
    "print(hero_vertical_extents)\n",
    "\n",
    "# Note that considering the standard deviations of the values in each row as a different means of\n",
    "# obtaining the vertical extents results in the same extents as those obtained here.\n",
    "\n",
    "# Show those values as white pixels to the right of the letters.  Offset the extents to ease\n",
    "# inspecting the shown image.\n",
    "def fn(image, t):\n",
    "    top, bottom = t\n",
    "    image = image.copy()\n",
    "    right = image.shape[1] // 2\n",
    "    image[:top, right:] = 1.0\n",
    "    image[bottom:, right:] = 1.0\n",
    "    return image\n",
    "image = np.vstack(list(it.starmap(fn, zip(hero_mean_images.values(), d.values()))))\n",
    "show_and_wait(image)\n",
    "cv2.destroyAllWindows()\n",
    "{k: (16*m+v[0],16*m+v[1],''if len(v)==2 else'not 2') for m, (k, v) in enumerate(d.items())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop the images to those vertical extents for the rest of the process.  This does not adversely\n",
    "# affect \"Queen of Pain\" since the descender of its \"Q\" is still visible.\n",
    "vertically_cropped_hero_mean_images = {k: v[hero_vertical_extents[k][0]:hero_vertical_extents[k][1], :] for k, v in hero_mean_images.items()}\n",
    "image = np.vstack(list(vertically_cropped_hero_mean_images.values()))\n",
    "show_and_wait(image)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ancient Apparition': (17, 117),\n",
       " 'Anti-Mage': (36, 98),\n",
       " 'Broodmother': (25, 109),\n",
       " 'Centaur Warrunner': (16, 118),\n",
       " 'Clinkz': (47, 87),\n",
       " 'Io': (61, 74),\n",
       " 'Juggernaut': (30, 104),\n",
       " 'Keeper of the Light': (17, 118),\n",
       " \"Nature's Prophet\": (15, 119),\n",
       " 'Nyx Assassin': (28, 106),\n",
       " 'Outworld Devourer': (17, 117),\n",
       " 'Queen of Pain': (24, 110)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the horizontal extents of the text in the images.  This is not the horizontal extents of\n",
    "# the letters.  This is the left edge of the left-most letter and the right edge of the\n",
    "# right-most letter.\n",
    "\n",
    "# Look for significant variations along the horizontal axis.  With the current limit, it also\n",
    "# captures the boundaries of the words.\n",
    "d = {k: np.std(v, axis=0) > 0.011 for k, v in vertically_cropped_hero_mean_images.items()}\n",
    "def fn(name, bools):\n",
    "    image = vertically_cropped_hero_mean_images[name].copy()\n",
    "    for i, b in enumerate(bools):\n",
    "        image[-1, i] = 1.0 if b else 0.0\n",
    "    return image\n",
    "show_and_wait(np.vstack([fn(k, v) for k, v in d.items()]))\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Take the first and last change to constitute the left and right edge of each image.\n",
    "def fn(bools):\n",
    "    g = it.dropwhile(lambda t: not t[1], enumerate(bools))\n",
    "    left = next(g)[0]\n",
    "    g = it.dropwhile(lambda t: not t[1], enumerate(reversed(bools)))\n",
    "    right = len(bools) - next(g)[0]\n",
    "    return left, right\n",
    "d = {k: fn(v) for k, v in d.items()}\n",
    "hero_horizontal_extents = d\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop the images to those horizontal extents for the rest of the process.\n",
    "fully_cropped_hero_mean_images = {k: v[:, hero_horizontal_extents[k][0]:hero_horizontal_extents[k][1]] for k, v in vertically_cropped_hero_mean_images.items()}\n",
    "fully_cropped_max_width = max(v.shape[1] for v in fully_cropped_hero_mean_images.values())\n",
    "image = np.vstack([np.hstack([v, np.zeros((v.shape[0], fully_cropped_max_width - v.shape[1]))]) for v in fully_cropped_hero_mean_images.values()])\n",
    "show_and_wait(image)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ancient Apparition': ((0, 7),\n",
       "  (7, 13),\n",
       "  (13, 19),\n",
       "  (19, 23),\n",
       "  (23, 28),\n",
       "  (28, 35),\n",
       "  (35, 41),\n",
       "  (43, 50),\n",
       "  (50, 56),\n",
       "  (56, 61),\n",
       "  (61, 67),\n",
       "  (67, 73),\n",
       "  (73, 77),\n",
       "  (77, 83),\n",
       "  (83, 86),\n",
       "  (86, 93),\n",
       "  (93, 100)),\n",
       " 'Anti-Mage': ((0, 8),\n",
       "  (8, 15),\n",
       "  (15, 23),\n",
       "  (23, 27),\n",
       "  (27, 32),\n",
       "  (32, 40),\n",
       "  (40, 48),\n",
       "  (48, 55),\n",
       "  (55, 62)),\n",
       " 'Broodmother': ((0, 6),\n",
       "  (6, 14),\n",
       "  (14, 22),\n",
       "  (22, 30),\n",
       "  (30, 38),\n",
       "  (38, 47),\n",
       "  (47, 56),\n",
       "  (56, 63),\n",
       "  (63, 70),\n",
       "  (70, 77),\n",
       "  (77, 84)),\n",
       " 'Centaur Warrunner': ((0, 6),\n",
       "  (6, 11),\n",
       "  (11, 18),\n",
       "  (18, 23),\n",
       "  (23, 30),\n",
       "  (30, 35),\n",
       "  (35, 42),\n",
       "  (44, 53),\n",
       "  (52, 59),\n",
       "  (59, 65),\n",
       "  (65, 71),\n",
       "  (71, 77),\n",
       "  (77, 84),\n",
       "  (84, 90),\n",
       "  (90, 95),\n",
       "  (95, 102)),\n",
       " 'Clinkz': ((0, 7), (7, 13), (13, 17), (17, 25), (25, 33), (33, 40)),\n",
       " 'Io': ((0, 4), (4, 13)),\n",
       " 'Juggernaut': ((0, 6),\n",
       "  (6, 14),\n",
       "  (14, 21),\n",
       "  (21, 29),\n",
       "  (29, 35),\n",
       "  (35, 43),\n",
       "  (43, 51),\n",
       "  (51, 59),\n",
       "  (59, 66),\n",
       "  (66, 74)),\n",
       " 'Keeper of the Light': ((0, 6),\n",
       "  (6, 11),\n",
       "  (11, 17),\n",
       "  (17, 23),\n",
       "  (23, 28),\n",
       "  (28, 34),\n",
       "  (36, 44),\n",
       "  (44, 50),\n",
       "  (51, 58),\n",
       "  (58, 65),\n",
       "  (65, 70),\n",
       "  (73, 78),\n",
       "  (78, 82),\n",
       "  (82, 88),\n",
       "  (88, 95),\n",
       "  (95, 101)),\n",
       " \"Nature's Prophet\": ((0, 8),\n",
       "  (8, 15),\n",
       "  (15, 22),\n",
       "  (22, 29),\n",
       "  (29, 36),\n",
       "  (36, 42),\n",
       "  (42, 45),\n",
       "  (45, 52),\n",
       "  (55, 61),\n",
       "  (61, 68),\n",
       "  (68, 77),\n",
       "  (76, 83),\n",
       "  (83, 91),\n",
       "  (91, 97),\n",
       "  (97, 104)),\n",
       " 'Nyx Assassin': ((0, 8),\n",
       "  (8, 15),\n",
       "  (15, 23),\n",
       "  (25, 34),\n",
       "  (34, 40),\n",
       "  (40, 46),\n",
       "  (46, 53),\n",
       "  (53, 59),\n",
       "  (59, 65),\n",
       "  (65, 69),\n",
       "  (69, 78)),\n",
       " 'Outworld Devourer': ((0, 7),\n",
       "  (7, 14),\n",
       "  (14, 19),\n",
       "  (19, 27),\n",
       "  (27, 34),\n",
       "  (34, 40),\n",
       "  (40, 45),\n",
       "  (45, 51),\n",
       "  (53, 60),\n",
       "  (60, 64),\n",
       "  (64, 71),\n",
       "  (71, 77),\n",
       "  (77, 84),\n",
       "  (84, 89),\n",
       "  (89, 94),\n",
       "  (94, 100)),\n",
       " 'Queen of Pain': ((0, 10),\n",
       "  (10, 17),\n",
       "  (17, 23),\n",
       "  (23, 30),\n",
       "  (30, 38),\n",
       "  (41, 50),\n",
       "  (50, 56),\n",
       "  (59, 66),\n",
       "  (66, 73),\n",
       "  (73, 77),\n",
       "  (77, 86))}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the horizontal extents of the letters.  Note that there are three instances of letters\n",
    "# having overlapping bright pixels due to kerning:  \"TA\" and \"WA\" in \"CENTAUR WARRUNNER\" and \"AT\"\n",
    "# in \"NATURE'S PROPHET\".\n",
    "\n",
    "# Find the maximum of each column for each hero's fully-cropped mean image.\n",
    "d = {k: [np.max(v[:, i]) for i in range(v.shape[1])] for k, v in fully_cropped_hero_mean_images.items()}\n",
    "hero_maxima = d\n",
    "\n",
    "# Assume maximum values below a threshold represent the spaces between the letters.\n",
    "hero_spaces = {k: [v < .312 for v in v] for k, v in hero_maxima.items()}\n",
    "\n",
    "# Show those values as white pixels below the letters.\n",
    "def fn(image, l):\n",
    "    image = image.copy()\n",
    "    for i, b in enumerate(l):\n",
    "        if b:\n",
    "            image[-1:, i] = 1.0\n",
    "    return image\n",
    "g = (it.starmap(fn, zip(fully_cropped_hero_mean_images.values(), hero_spaces.values())))\n",
    "show_and_wait(np.vstack([np.hstack([v, np.zeros((v.shape[0], fully_cropped_max_width - v.shape[1]))]) for v in g]))\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Determine the horizontal letter extents.\n",
    "def fn(name, l):\n",
    "    # Ignore maxima that occur at the beginning of the image.\n",
    "    for i, _ in enumerate(it.takewhile(lambda v: v, l)):\n",
    "        l[i] = False\n",
    "\n",
    "    # Ignore maxima that occur at the end of the image.\n",
    "    for i, _ in enumerate(it.takewhile(lambda v: v, reversed(l))):\n",
    "        l[~i] = False\n",
    "\n",
    "    g = (a ^ b for a, b in it.pairwise(l))\n",
    "    g = (i + 1 for i, b in enumerate(g) if b)\n",
    "    g = it.chain([0], g, [fully_cropped_hero_mean_images[name].shape[1]])\n",
    "    l = list(g)\n",
    "    if len(l) % 2:\n",
    "        raise AssertionError()\n",
    "    for i in range(1, len(l) - 1, 2):\n",
    "        j = i + 1\n",
    "        diff = l[j] - l[i]\n",
    "        if diff:\n",
    "            l[i] += 2 if 2 < diff < 4 else 1\n",
    "            l[j] -= 1 if diff > 1 else 0\n",
    "    g = iter(l)\n",
    "    g = zip(g, g)\n",
    "\n",
    "    # Convert the elements from tuples to lists since I need to apply fix-ups.\n",
    "    return [list(t) for t in g]\n",
    "hero_horizontal_letter_extents = {k: fn(k, v) for k, v in hero_spaces.items()}\n",
    "\n",
    "# Add extents for the kerned pairs.\n",
    "l = hero_horizontal_letter_extents['Centaur Warrunner']\n",
    "l = l[:3] + [[l[3][0], 23], [23, l[3][1]]] + l[4:6] + [[l[6][0], 52], [52, l[6][1]]] + l[7:]\n",
    "hero_horizontal_letter_extents['Centaur Warrunner'] = l\n",
    "l = hero_horizontal_letter_extents[\"Nature's Prophet\"]\n",
    "l = l[:1] + [[l[1][0], 15], [15, l[1][1]]] + l[2:]\n",
    "hero_horizontal_letter_extents[\"Nature's Prophet\"] = l\n",
    "\n",
    "# Add other fix-ups.\n",
    "hero_horizontal_letter_extents['Centaur Warrunner'][7][1] += 1 # This will require an image fix-up.\n",
    "hero_horizontal_letter_extents['Keeper of the Light'][7][1] += 1\n",
    "hero_horizontal_letter_extents[\"Nature's Prophet\"][0][1] += 1\n",
    "hero_horizontal_letter_extents[\"Nature's Prophet\"][1][0] += 1\n",
    "hero_horizontal_letter_extents[\"Nature's Prophet\"][7][1] += 1\n",
    "hero_horizontal_letter_extents[\"Nature's Prophet\"][10][1] += 1\n",
    "\n",
    "# Convert the elements and their sub-elements to tuples.\n",
    "hero_horizontal_letter_extents = {k: tuple(tuple(l) for l in v) for k, v in hero_horizontal_letter_extents.items()}\n",
    "\n",
    "def fn(name, extents):\n",
    "    image = np.zeros((2, fully_cropped_hero_mean_images[name].shape[1]))\n",
    "    for i, (left, right) in enumerate(extents):\n",
    "        image[i % 2, left:right] = 1.0\n",
    "    return np.vstack([fully_cropped_hero_mean_images[name], image])\n",
    "g = (fn(k, v) for k, v in hero_horizontal_letter_extents.items())\n",
    "show_and_wait(np.vstack([np.hstack([v, np.zeros((v.shape[0], fully_cropped_max_width - v.shape[1]))]) for v in g]))\n",
    "cv2.destroyAllWindows()\n",
    "hero_horizontal_letter_extents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"'\": (1, '3'),\n",
       " '-': (1, '5'),\n",
       " 'A': (12, '7 7 6 8 8 7 7 8 7 9 7 7'),\n",
       " 'B': (1, '6'),\n",
       " 'C': (3, '6 6 7'),\n",
       " 'D': (3, '8 6 7'),\n",
       " 'E': (16, '5 7 7 5 5 6 5 6 5 5 6 6 4 5 6 7'),\n",
       " 'F': (2, '6 6'),\n",
       " 'G': (4, '7 7 8 6'),\n",
       " 'H': (4, '7 7 7 8'),\n",
       " 'I': (9, '4 4 3 4 4 4 4 4 4'),\n",
       " 'J': (1, '6'),\n",
       " 'K': (2, '8 6'),\n",
       " 'L': (3, '6 5 5'),\n",
       " 'M': (2, '8 9'),\n",
       " 'N': (14, '6 7 7 7 7 7 6 8 8 8 8 9 8 9'),\n",
       " 'O': (11, '7 8 8 9 9 8 9 7 7 6 9'),\n",
       " 'P': (6, '6 5 6 6 7 7'),\n",
       " 'Q': (1, '10'),\n",
       " 'R': (14, '6 8 7 7 6 6 7 8 6 7 7 6 5 6'),\n",
       " 'S': (5, '7 6 6 6 6'),\n",
       " 'T': (11, '6 6 8 7 5 8 7 6 7 7 5'),\n",
       " 'U': (8, '5 6 8 7 7 7 7 7'),\n",
       " 'V': (1, '7'),\n",
       " 'W': (2, '9 8'),\n",
       " 'X': (1, '8'),\n",
       " 'Y': (1, '7'),\n",
       " 'Z': (1, '7')}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the letter images for each Hero using the uncropped mean images.\n",
    "\n",
    "def fn(name, text_left):\n",
    "    image = hero_mean_images[name]\n",
    "    g = ((text_left + left, text_left + right) for left, right in hero_horizontal_letter_extents[name])\n",
    "    letter_images = [image[:, left:right] for left, right in g]\n",
    "\n",
    "    # Fix up the \"W\" in \"CENTAUR WARRUNNER\".\n",
    "    if name == 'Centaur Warrunner':\n",
    "        row = hero_vertical_extents[name][1] - 3\n",
    "        letter_images[7][row, -1] = letter_images[7][row + 1, -1]\n",
    "\n",
    "    return letter_images\n",
    "d = {name: fn(name, left) for name, (left, _) in hero_horizontal_extents.items()}\n",
    "\n",
    "# Verify the count of the letter images.\n",
    "g = ((ilen(c for c in name if c != ' '), len(l)) for name, l in d.items())\n",
    "if any(a != b for a, b in g):\n",
    "    raise AssertionError()\n",
    "\n",
    "# Organize the letter images by letter.\n",
    "g = it.chain.from_iterable((zip((c.upper() for c in k if c != ' '), v)) for k, v in d.items())\n",
    "l = sorted(g, key=lambda t: t[0])\n",
    "g = it.groupby(l, key=lambda t: t[0])\n",
    "d = {k: [v for _, v in v] for k, v in g}\n",
    "\n",
    "max_width = max(np.hstack(l).shape[1] for l in d.values())\n",
    "l = [np.hstack(l + [np.zeros((l[0].shape[0], max_width - np.hstack(l).shape[1]))]) for l in d.values()]\n",
    "show_and_wait(np.vstack(l))\n",
    "cv2.destroyAllWindows()\n",
    "hero_letter_images = d\n",
    "{k: (len(v), ' '.join([str(i.shape[1]) for i in v])) for k, v in hero_letter_images.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"'\": (1, '3'),\n",
       " '-': (1, '5'),\n",
       " 'A': (12, '7 7 6 8 8 7 7 8 7 9 7 7'),\n",
       " 'B': (1, '6'),\n",
       " 'C': (3, '6 6 7'),\n",
       " 'D': (3, '8 6 7'),\n",
       " 'E': (16, '5 7 7 5 5 6 5 6 5 5 6 6 4 5 6 7'),\n",
       " 'F': (2, '6 6'),\n",
       " 'G': (4, '7 7 8 6'),\n",
       " 'H': (4, '7 7 7 8'),\n",
       " 'I': (9, '4 4 3 4 4 4 4 4 4'),\n",
       " 'J': (1, '6'),\n",
       " 'K': (2, '8 6'),\n",
       " 'L': (3, '6 5 5'),\n",
       " 'M': (2, '8 9'),\n",
       " 'N': (14, '6 7 7 7 7 7 6 8 8 8 8 9 8 9'),\n",
       " 'O': (11, '7 8 8 9 9 8 9 7 7 6 9'),\n",
       " 'P': (6, '6 5 6 6 7 7'),\n",
       " 'Q': (1, '10'),\n",
       " 'R': (14, '6 8 7 7 6 6 7 8 6 7 7 6 5 6'),\n",
       " 'S': (5, '7 6 6 6 6'),\n",
       " 'T': (11, '6 6 8 7 5 8 7 6 7 7 5'),\n",
       " 'U': (8, '5 6 8 7 7 7 7 7'),\n",
       " 'V': (1, '7'),\n",
       " 'W': (2, '9 8'),\n",
       " 'X': (1, '8'),\n",
       " 'Y': (1, '7'),\n",
       " 'Z': (1, '7')}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a mask for each letter.\n",
    "\n",
    "# The shifted cube root looks good.\n",
    "def linear(v):\n",
    "    return v\n",
    "def sqrt(v):\n",
    "    return np.sqrt(v)\n",
    "def curt(v):\n",
    "    return pow(v, 1/3)\n",
    "def sigmoid(v):\n",
    "    return 1 / (1 + np.exp(-v))\n",
    "def adjusted_sigmoid(v):\n",
    "    v = sigmoid(v - 0.125)\n",
    "    min, max = np.min(v), np.max(v)\n",
    "    return (v - min) / (max - min)\n",
    "def shifted_sqrt(v):\n",
    "    v = v.copy()\n",
    "    v -= 0.2\n",
    "    v[v < 0] = 0\n",
    "    return np.sqrt(v / 0.8)\n",
    "def shifted_curt(v):\n",
    "    v = v.copy()\n",
    "    v -= 0.1\n",
    "    v[v < 0] = 0\n",
    "    return pow(v / 0.9, 1/3)\n",
    "\n",
    "# Create a mask from the pixels that are outside of the standard deviation of the grey background\n",
    "# of pixels in the second and third rows.  Do this for each image since their grey backgrounds are\n",
    "# different from each other.\n",
    "def fn(image):\n",
    "    mean, std = np.mean(image[2:4, :]), np.std(image[2:4, :])\n",
    "    image = np.abs(image - mean) / std\n",
    "    image = shifted_curt(image / np.max(image))\n",
    "    return image.astype(np.float32)\n",
    "d = {k: list(map(fn, v)) for k, v in hero_letter_images.items()}\n",
    "l = [np.hstack(l + [np.zeros((l[0].shape[0], max_width - np.hstack(l).shape[1]))]) for l in d.values()]\n",
    "show_and_wait(np.vstack(l))\n",
    "cv2.destroyAllWindows()\n",
    "hero_letter_masks = d\n",
    "{k: (len(v), ' '.join([str(i.shape[1]) for i in v])) for k, v in hero_letter_masks.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a dictionary of letters to 2-tuples of the tuple of letter images and the tuple of masks.\n",
    "def fn(l):\n",
    "    return tuple(map(tuple, l))\n",
    "d = {k: (fn(hero_letter_images[k]), fn(v)) for k, v in hero_letter_masks.items()}\n",
    "with open(r\"F:\\Dota 2\\Heroes\\letters.pickle\", 'bw') as fout:\n",
    "    pickle.dump(d, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Stop here.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m()\n",
      "\u001b[1;31mValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Stop here.\n",
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the code is archived and not used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(r\"C:\\Users\\Chris\\Pictures\\tesst.png\", image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a masking factor for each hero.  A masking factor is the stability of the pixels in an\n",
    "# image.  The more stable the pixel, the higher is the value of the masking factor for that pixel.\n",
    "# I tried using the variance instead of the standard deviation but it has too much noise.\n",
    "directory_path = r'F:\\Dota 2\\Heroes\\Pictures'\n",
    "def fn(file_title):\n",
    "    def fn(file_name: str):\n",
    "        # Read the image.\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        image = cv2.imread(file_path)\n",
    "\n",
    "        # Color data adds no value to this methodology.\n",
    "        # Take the color channel with the lowest value.  This changes\n",
    "        # the shape of the image from (60, 160, 3) to (60, 160).\n",
    "        return image[:, :, np.argmin(np.sum(image, axis=(0, 1)))]\n",
    "\n",
    "    # Read and process all files in the Pictures directory for the given file title.\n",
    "    _, _, file_names = next(os.walk(directory_path))\n",
    "    g = (file_name for file_name in file_names if file_name.startswith(file_title))\n",
    "    images = list(map(fn, g))\n",
    "\n",
    "    # Combine the list of two-dimensional tensors into a single three-dimensional tensor.\n",
    "    images = np.stack(images, axis=0)\n",
    "\n",
    "    # Determine the desired factor by scaling the range of standard deviations\n",
    "    # of the sum of all values in each image from [max, min] to [0, 1].\n",
    "    std = np.std(images, axis=0)\n",
    "    desired_factor = (std - np.max(std)) / (np.min(std) - np.max(std))\n",
    "\n",
    "    # Clean up the edges.\n",
    "    desired_factor[-1, :] = 0\n",
    "\n",
    "    # Apply a threshold to remove the background.\n",
    "    image = (desired_factor * 255).astype(np.uint8)\n",
    "    threshold, image = cv2.threshold(image, 0, 0, cv2.THRESH_TOZERO | cv2.THRESH_OTSU)\n",
    "    while np.any(image[:, :16]):\n",
    "        threshold *= 1.1\n",
    "        print('updating', file_title, 'to', threshold)\n",
    "        _, image = cv2.threshold(image, threshold, 0, cv2.THRESH_TOZERO)\n",
    "    desired_factor = image.astype(np.float32) / 255\n",
    "    return desired_factor\n",
    "\n",
    "data = {s: fn(s) for s in file_titles}\n",
    "\n",
    "show_and_wait(np.vstack(list(data.values())))\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the vertical extent of the text in each image.\n",
    "def fn(name, image):\n",
    "    a = image.astype(np.float32)\n",
    "    a = np.max(a[1:], axis=1) - np.max(a[:-1], axis=1)\n",
    "    return name, np.argmax(a) + 1, np.argmin(a) + 1\n",
    "hero_vertical_extents = {name: (top, bottom) for name, top, bottom in it.starmap(fn, data.items())}\n",
    "hero_vertical_extents\n",
    "# I don't need these since my masks are all black above and below the letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider the standard deviations of the values in each row.  That might provide a better idea of\n",
    "# the vertical extents.\n",
    "d= {k: np.std(v, axis=1) for k, v in hero_mean_images.items()}\n",
    "d = {k: v < 0.0125 for k, v in d.items()}\n",
    "d = {k: [i + 1 for i, b in enumerate(v[:-1] ^ v[1:]) if b] for k, v in d.items()}\n",
    "\n",
    "# Show those values as white pixels to the right of the letters.\n",
    "def fn(image, t):\n",
    "    top, bottom = t\n",
    "    image = image.copy()\n",
    "    right = image.shape[1] // 2\n",
    "    image[:top, right:] = 1.0\n",
    "    image[bottom:, right:] = 1.0\n",
    "    return image\n",
    "image = np.vstack(list(it.starmap(fn, zip(hero_mean_images.values(), d.values()))))\n",
    "show_and_wait(image)\n",
    "cv2.destroyAllWindows()\n",
    "{k: (16*m+v[0],16*m+v[1],''if len(v)==2 else'not 2') for m, (k, v) in enumerate(d.items())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a file that multiple processes can partially load.\n",
    "file_path = r\"D:\\Dota 2\\Heroes\\Pickles\\letter_images.pickle\"\n",
    "if not os.access(file_path, os.F_OK):\n",
    "    with open(file_path, 'wb') as fout:\n",
    "        # Write a dictionary of letter image counts.\n",
    "        pickle.dump({k: len(v) for k, v, in letter_images.items()}, fout)\n",
    "        # Write each letter's images in lexical order.\n",
    "        for k, v in sorted(letter_images.items()):\n",
    "            print(k, len(v))\n",
    "            pickle.dump(tuple(v), fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test partial loading.\n",
    "def fn():\n",
    "    with open(file_path, 'rb') as fin:\n",
    "        # Read the letter image count dictionary.\n",
    "        d = pickle.load(fin)\n",
    "        # Read a fraction of the images for each letter.\n",
    "        d = {k: random.sample(pickle.load(fin), k=9999) for k in sorted(d)}\n",
    "    return d\n",
    "sampled_letter_images = fn()\n",
    "[(k, len(v)) for k, v in sampled_letter_images.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of letters to images for each extent extracted from each image in each video file.\n",
    "# Distinguish between large and small letter renderings by using an upper-case letter for the large ones and\n",
    "# a lower-case letter for the small ones.\n",
    "small_letters = {\n",
    "    'ancient_apparition',\n",
    "    'centaur_warrunner',\n",
    "    'keeper_of_the_light',\n",
    "    'outworld_devourer',\n",
    "}\n",
    "def fn():\n",
    "    file_path = r\"D:\\Dota 2\\Heroes\\Pickles\\sized_letter_images.pickle\"\n",
    "    if os.access(file_path, os.F_OK):\n",
    "        with open(file_path, 'rb') as fin:\n",
    "            # Read the dictionary of letter image counts.\n",
    "            d = pickle.load(fin)\n",
    "            # Read each letter's images in lexical order.\n",
    "            for k in sorted(d):\n",
    "                d[k] = pickle.load(fin)\n",
    "    else:\n",
    "        # Create a file that multiple processes can partially load.\n",
    "        d = collections.defaultdict(list)\n",
    "        for file_title, images in data.items():\n",
    "            file_extents = selected_extents[file_title]\n",
    "            letters = [c if file_title in small_letters else c.upper() for c in file_title if c != '_']\n",
    "            for (left, right), letter in zip(file_extents, letters):\n",
    "                for image in images:\n",
    "                    image = cv2.threshold(image, 0, 0, cv2.THRESH_TOZERO | cv2.THRESH_OTSU)[1]\n",
    "                    image = image[:, left:right]\n",
    "                    d[letter].append(image)\n",
    "        with open(file_path, 'wb') as fout:\n",
    "            # Write a dictionary of letter image counts.\n",
    "            pickle.dump({k: len(v) for k, v, in d.items()}, fout)\n",
    "            # Write each letter's images in lexical order.\n",
    "            for k, v in sorted(d.items()):\n",
    "                print(k, len(v))\n",
    "                pickle.dump(tuple(v), fout)\n",
    "    return d\n",
    "sized_letter_images = fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*sorted(sized_letter_images))\n",
    "def fn(fn):\n",
    "    all_letters = {fn(chr(i)) for i in range(ord('A'), ord('Z') + 1)}\n",
    "    given_letters = {c for c in sized_letter_images if c == fn(c)}\n",
    "    missing_letters = all_letters - given_letters\n",
    "    print('missing', len(missing_letters), sorted(missing_letters))\n",
    "fn(str.upper)\n",
    "fn(str.lower)\n",
    "[(k, len(v)) for k, v in sorted(sized_letter_images.items())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display examples of each letter.\n",
    "display_examples(sized_letter_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the minimum number of zeros to include images.\n",
    "class Finder:\n",
    "    def __init__(self, images):\n",
    "        self.__nzeros = [image.sum() for image in images]\n",
    "        self.__len = op.mul(*images[0].shape[:2])\n",
    "        self.__n = len(images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        l = [nzeros for nzeros in self.__nzeros if nzeros >= index]\n",
    "        return 1 if len(l) * 10 < self.__n else -1\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.__len\n",
    "\n",
    "def fn(file_title, file_images):\n",
    "    print(file_title)\n",
    "    file_images = [cv2.threshold(i, 0, 0, cv2.THRESH_TOZERO | cv2.THRESH_OTSU)[1] == 0 for i in file_images]\n",
    "    letters = [c if file_title in small_letters else c.upper() for c in file_title if c != '_']\n",
    "    def fn(t):\n",
    "        index, horizontal_extent = t\n",
    "        left, right = horizontal_extent\n",
    "        #letter_images = [image[4:-3, left:right] for image in file_images]\n",
    "        #minimum_nzero = (file_images[0].shape[0] - 7) * -op.sub(*selected_extents[file_title][1]) // 2\n",
    "        letter_images = [image[:, left:right] for image in file_images]\n",
    "        minimum_nzero = bisect.bisect_left(Finder(letter_images), 0)\n",
    "        return index, minimum_nzero - 1\n",
    "    file_extents = selected_extents[file_title]\n",
    "    d = dict(map(fn, enumerate(file_extents)))\n",
    "    return d\n",
    "#minimum_nzeros = {k: fn(k, v) for k, v in data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the minimum numbers of zeros created above.\n",
    "minimum_nzeros = {\n",
    "    'ancient_apparition': {0: 86, 1: 100, 2: 87, 3: 43, 4: 56, 5: 82, 6: 87, 7: 101, 8: 69, 9: 70, 10: 101, 11: 82, 12: 43, 13: 87, 14: 43, 15: 97, 16: 82},\n",
    "    'anti-mage': {0: 114, 1: 94, 2: 101, 3: 42, 4: 62, 5: 106, 6: 111, 7: 96, 8: 68},\n",
    "    'broodmother': {0: 79, 1: 79, 2: 108, 3: 110, 4: 90, 5: 106, 6: 108, 7: 101, 8: 96, 9: 68, 10: 91},\n",
    "    'centaur_warrunner': {0: 87, 1: 69, 2: 99, 3: 87, 4: 70, 5: 85, 6: 83, 7: 127, 8: 70, 9: 67, 10: 67, 11: 83, 12: 82, 13: 84, 14: 69, 15: 83},\n",
    "    'clinkz': {0: 99, 1: 82, 2: 52, 3: 94, 4: 95, 5: 82},\n",
    "    'io': {0: 42, 1: 108},\n",
    "    'juggernaut': {0: 72, 1: 96, 2: 96, 3: 98, 4: 79, 5: 79, 6: 94, 7: 114, 8: 94, 9: 101},\n",
    "    'keeper_of_the_light': {0: 85, 1: 69, 2: 72, 3: 69, 4: 71, 5: 82, 6: 95, 7: 70, 8: 88, 9: 84, 10: 72, 11: 73, 12: 43, 13: 87, 14: 84, 15: 88},\n",
    "    \"nature's_prophet\": {0: 94, 1: 98, 2: 85, 3: 80, 4: 92, 5: 79, 6: 46, 7: 83, 8: 77, 9: 80, 10: 110, 11: 83, 12: 94, 13: 79, 14: 101},\n",
    "    'nyx_assassin': {0: 93, 1: 100, 2: 95, 3: 97, 4: 84, 5: 84, 6: 111, 7: 81, 8: 81, 9: 52, 10: 94},\n",
    "    'outworld_devourer': {0: 99, 1: 83, 2: 87, 3: 115, 4: 97, 5: 69, 6: 70, 7: 81, 8: 81, 9: 68, 10: 88, 11: 99, 12: 83, 13: 83, 14: 70, 15: 69},\n",
    "    'queen_of_pain': {0: 134, 1: 79, 2: 79, 3: 67, 4: 93, 5: 123, 6: 81, 7: 82, 8: 95, 9: 52, 10: 94},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the images resulting from applying the minimum numbers of zeros.\n",
    "def fn(file_title, index, minimum_nzeros):\n",
    "    g = (image for image in data[file_title])\n",
    "    g = (cv2.threshold(image, 0, 0, cv2.THRESH_TOZERO | cv2.THRESH_OTSU)[1] for image in g)\n",
    "    left, right = selected_extents[file_title][index]\n",
    "    g = (image[:, left:right] for image in g)\n",
    "    g = (image for image in g if minimum_nzeros * 1.1 > (image == 0).sum() >= minimum_nzeros)\n",
    "    g = next(grouper(g, 1200))\n",
    "    image = np.vstack([np.hstack(list(g)) for g in grouper(g, 60)])\n",
    "    #print(file_title, index, minimum_nzeros, [c for c in file_title if c != '_'][index].upper())\n",
    "    return show_and_wait(image)\n",
    "g = ((s, i, m) for s in file_titles for i, m in sorted(minimum_nzeros[s].items()))\n",
    "list(it.takewhile(lambda t: fn(*t) != 'q', g))\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of clean letters to images for each extent extracted from each image in each video file.\n",
    "# Distinguish between large and small letter renderings by using an upper-case letter for the large ones and\n",
    "# a lower-case letter for the small ones.\n",
    "def fn():\n",
    "    file_path = r\"D:\\Dota 2\\Heroes\\Pickles\\clean_letter_images.pickle\"\n",
    "    if os.access(file_path, os.F_OK):\n",
    "        with open(file_path, 'rb') as fin:\n",
    "            # Read the dictionary of letter image counts.\n",
    "            d = pickle.load(fin)\n",
    "            # Read each letter's images in lexical order.\n",
    "            for k in sorted(d):\n",
    "                d[k] = pickle.load(fin)\n",
    "        print({k: len(v) for k, v, in d.items()})\n",
    "    else:\n",
    "        # Create a file that multiple processes can partially load.\n",
    "        d = collections.defaultdict(list)\n",
    "        for file_title, images in data.items():\n",
    "            file_minimum_nzeros = minimum_nzeros[file_title]\n",
    "            l = [cv2.threshold(image, 0, 0, cv2.THRESH_TOZERO | cv2.THRESH_OTSU)[1] for image in images]\n",
    "            file_extents = selected_extents[file_title]\n",
    "            letters = [c if file_title in small_letters else c.upper() for c in file_title if c != '_']\n",
    "            for (left, right), (index, letter) in zip(file_extents, enumerate(letters)):\n",
    "                m = file_minimum_nzeros[index]\n",
    "                for image in l:\n",
    "                    image = image[:, left:right]\n",
    "                    if m * 1.1 > (image == 0).sum() >= m:\n",
    "                        d[letter].append(image)\n",
    "        with open(file_path, 'wb') as fout:\n",
    "            # Write a dictionary of letter image counts.\n",
    "            pickle.dump({k: len(v) for k, v, in d.items()}, fout)\n",
    "            # Write each letter's images in lexical order.\n",
    "            for k, v in sorted(d.items()):\n",
    "                print(k, len(v))\n",
    "                pickle.dump(tuple(v), fout)\n",
    "    return d\n",
    "clean_letter_images = fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect clean letter images.\n",
    "def fn():\n",
    "    for letter, images in clean_letter_images.items():\n",
    "        image = np.vstack([np.hstack(list(g)) for g in grouper(images[:1200], 60)])\n",
    "        print(letter)\n",
    "        if show_and_wait(image) == 'q':\n",
    "            break\n",
    "#fn()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_margin = 5\n",
    "def put_text(background: np.ndarray, text: str, letter_images):\n",
    "    image = background.copy()\n",
    "\n",
    "    # Construct the image of the text.\n",
    "    dtype, height, width = image.dtype, *image.shape\n",
    "    def make_letter(letter):\n",
    "        image = random.choice(letter_images[letter])\n",
    "        return image\n",
    "    def make_space():\n",
    "        # Randomly add to the text about one space for every five characters.\n",
    "        width = random.randint(7, 8) if random.random() < .167 else random.randint(0, 1)\n",
    "        image = np.zeros((height, width), dtype)\n",
    "        return image\n",
    "    def fn():\n",
    "        a = map(make_letter, text)\n",
    "        b = (make_space() for _ in text)\n",
    "        g = it.chain.from_iterable(zip(a, b))\n",
    "        image = np.hstack(list(g)[:-1])\n",
    "        if image.shape[1] < width - 2 * horizontal_margin:\n",
    "            # Select a random position for the rendered text in the background.\n",
    "            left = random.randrange(horizontal_margin, width - horizontal_margin - image.shape[1])\n",
    "            right = width - image.shape[1] - left\n",
    "            return np.hstack([np.zeros((height, left), dtype), image, np.zeros((height, right), dtype)])\n",
    "    text_image = fn()\n",
    "    if text_image is None:\n",
    "        # The text renders too wide.  Try again.\n",
    "        return\n",
    "\n",
    "    # Apply the rendered greyscale text to the background.\n",
    "    image = image * (text_image == 0) + text_image\n",
    "    image = cv2.threshold(image, 0, 0, cv2.THRESH_TOZERO | cv2.THRESH_OTSU)[1]\n",
    "    image = image * (text_image == 0) + text_image\n",
    "\n",
    "    # Add the removed dimension.\n",
    "    image = image[:, :, np.newaxis]\n",
    "\n",
    "    return image\n",
    "image = put_text(np.zeros((16, 120), np.uint8), 'ACDEF', clean_letter_images)\n",
    "show_and_wait(image)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 1200 of each letter.\n",
    "# Manually select ranges of images to exclude.\n",
    "nimages = 1200\n",
    "ncolumns = 60\n",
    "window_name = 'tesst'\n",
    "cv2.namedWindow(window_name, cv2.WINDOW_NORMAL | cv2.WINDOW_GUI_EXPANDED)\n",
    "def fn(file_title, horizontal_extent):\n",
    "    images = data[file_title]\n",
    "    indices = list(range(nimages))\n",
    "    left, right = horizontal_extent\n",
    "    def fn():\n",
    "        g = (cv2.threshold(images[i], 0, 0, cv2.THRESH_TOZERO | cv2.THRESH_OTSU)[1][:, left:right] for i in indices)\n",
    "        g = grouper(g, ncolumns)\n",
    "        return np.vstack([np.hstack(list(g)) for g in g])\n",
    "    initial_index = []\n",
    "    height, width = images[0].shape[0], right - left\n",
    "    def handle_mouse_event(event, x, y, *_):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            initial_index.clear()\n",
    "            initial_index.append((y // height) * ncolumns + x // width)\n",
    "        elif event == cv2.EVENT_RBUTTONDOWN:\n",
    "            index = (y // height) * ncolumns + x // width\n",
    "            begin, end = initial_index[0] if initial_index else index, index + 1\n",
    "            del indices[begin:end]\n",
    "            begin = indices[-1] + 1\n",
    "            end = begin + nimages - len(indices)\n",
    "            indices.extend(range(begin, end))\n",
    "            cv2.imshow(window_name, fn())\n",
    "            initial_index.clear()\n",
    "    cv2.setMouseCallback(window_name, handle_mouse_event)\n",
    "    show_and_wait(fn())\n",
    "    return indices\n",
    "#fn('io', selected_extents['io'][1])\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 1200 of each letter.\n",
    "# Manually select the minimum number of zeros to include images.\n",
    "nimages = 1200\n",
    "ncolumns = 60\n",
    "window_name = 'tesst'\n",
    "cv2.namedWindow(window_name, cv2.WINDOW_NORMAL | cv2.WINDOW_GUI_EXPANDED)\n",
    "def fn(file_title, horizontal_extent):\n",
    "    images = data[file_title]\n",
    "    minimum_nzero = images[0].shape[0] * -op.sub(*selected_extents[file_title][1]) // 2\n",
    "    left, right = horizontal_extent\n",
    "    def fn():\n",
    "        l = random.sample(images, len(images))\n",
    "        g = (cv2.threshold(image, 0, 0, cv2.THRESH_TOZERO | cv2.THRESH_OTSU)[1] for image in l)\n",
    "        g = (image[:, left:right] for image in g)\n",
    "        return [image for image in g if (image == 0).sum() >= minimum_nzero]\n",
    "    while True:\n",
    "        l = fn()\n",
    "        if len(l) < nimages:\n",
    "            image = np.zeros([1, 1], dtype=images[0].dtype)\n",
    "        else:\n",
    "            image = np.vstack([np.hstack(list(g)) for g in grouper(l[:nimages], ncolumns)])\n",
    "        ch = show_and_wait(image)\n",
    "        if ch == '-':\n",
    "            minimum_nzero -= 1\n",
    "        elif ch == '+':\n",
    "            minimum_nzero += 1\n",
    "        elif ch == '/':\n",
    "            minimum_nzero -= 10\n",
    "        elif ch == '*':\n",
    "            minimum_nzero += 10\n",
    "        elif ch == 'p':\n",
    "            print(minimum_nzero, len(l))\n",
    "        elif ch == 'q':\n",
    "            return minimum_nzero, len(fn())\n",
    "#print(fn('io', selected_extents['io'][1]))\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
