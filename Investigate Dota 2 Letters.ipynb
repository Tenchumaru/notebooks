{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "import collections\n",
    "import cv2\n",
    "import itertools as it\n",
    "import numpy as np\n",
    "import operator as op\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "def show_and_wait(image):\n",
    "    cv2.imshow('tesst', image)\n",
    "    cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_titles = [\n",
    "    'Ancient Apparition',\n",
    "    'Anti-Mage',\n",
    "    'Broodmother',\n",
    "    'Centaur Warrunner',\n",
    "    'Clinkz',\n",
    "    'Io',\n",
    "    'Juggernaut',\n",
    "    'Keeper of the Light',\n",
    "    \"Nature's Prophet\",\n",
    "    'Nyx Assassin',\n",
    "    'Outworld Devourer',\n",
    "    'Queen of Pain',\n",
    "]\n",
    "s = {c.lower() for c, _ in it.groupby(sorted(it.chain.from_iterable(file_titles)))}\n",
    "print(len(file_titles), ''.join(sorted(s)), len(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = r'F:\\Dota 2\\Heroes\\Pictures'\n",
    "def fn(file_title):\n",
    "    def fn(file_name: str):\n",
    "        # Read the image.\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        image = cv2.imread(file_path)\n",
    "\n",
    "        # Color data adds no value to this methodology.\n",
    "        # Take the color channel with the lowest value.  This changes\n",
    "        # the shape of the image from (60, 160, 3) to (60, 160).\n",
    "        return image[:, :, np.argmin(np.sum(image, axis=(0, 1)))]\n",
    "\n",
    "    # Read and process all files in the Pictures directory for the given file title.\n",
    "    _, _, file_names = next(os.walk(directory_path))\n",
    "    g = (file_name for file_name in file_names if file_name.startswith(file_title))\n",
    "    images = list(map(fn, g))\n",
    "\n",
    "    # Combine the list of two-dimensional tensors into a single three-dimensional tensor.\n",
    "    images = np.stack(images, axis=0)\n",
    "\n",
    "    # Determine the desired factor by scaling the range of standard deviations\n",
    "    # of the sum of all values in each image from [max, min] to [0, 1].\n",
    "    std = np.std(images, axis=0)\n",
    "    desired_factor = (std - np.max(std)) / (np.min(std) - np.max(std))\n",
    "\n",
    "    # Clean up the edges.\n",
    "    desired_factor[-1, :] = 0\n",
    "\n",
    "    # Apply a threshold to remove the background.\n",
    "    image = (desired_factor * 255).astype(np.uint8)\n",
    "    threshold, image = cv2.threshold(image, 0, 0, cv2.THRESH_TOZERO | cv2.THRESH_OTSU)\n",
    "    while np.any(image[:, :16]):\n",
    "        threshold *= 1.1\n",
    "        print('updating', file_title, 'to', threshold)\n",
    "        _, image = cv2.threshold(image, threshold, 0, cv2.THRESH_TOZERO)\n",
    "    desired_factor = image.astype(np.float32) / 255\n",
    "    return desired_factor\n",
    "\n",
    "data = {s: fn(s) for s in file_titles}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_and_wait(np.vstack(list(data.values())))\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the vertical extent of the text in each image.\n",
    "def fn(name, image):\n",
    "    a = image.astype(np.float32)\n",
    "    a = np.max(a[1:], axis=1) - np.max(a[:-1], axis=1)\n",
    "    return name, np.argmax(a) + 1, np.argmin(a) + 1\n",
    "vertical_extents = {name: (top, bottom) for name, top, bottom in it.starmap(fn, data.items())}\n",
    "vertical_extents\n",
    "# I don't need these since my masks are all black above and below the letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the horizontal extent of each letter in each image.\n",
    "def fn(name, image):\n",
    "    # Count the number of non-space characters.\n",
    "    n = len([c for c in name if c != ' '])\n",
    "\n",
    "    # Compute the max along the vertical axis to get a brightness profile\n",
    "    image = np.max(image, axis=0)\n",
    "\n",
    "    # Loop by a small increment and determine the number of crossings across the limit.\n",
    "    max_limit = np.max(image)\n",
    "    g = (max_limit * i / 999 for i in range(1000))\n",
    "    def fn(limit):\n",
    "        a = image < limit\n",
    "        a = a[1:] ^ a[:-1]\n",
    "        return np.sum(a) // 2\n",
    "    g = it.dropwhile(lambda t: t[1] < n, enumerate(map(fn, g)))\n",
    "    limit = max_limit * next(g)[0] / 999\n",
    "\n",
    "    # Collect the indices of where the image value crosses above then below the limit.\n",
    "    # These constitute the left and right edges of the letters.\n",
    "    edge = 'left'\n",
    "    l = []\n",
    "    for i, v in enumerate(image):\n",
    "        if edge == 'left' and v >= limit:\n",
    "            # Take a one-pixel margin to the left.\n",
    "            l.append(i - 1)\n",
    "            edge = 'right'\n",
    "        elif edge == 'right' and v < limit:\n",
    "            # Take a one-pixel margin to the right.\n",
    "            l.append(i + 1)\n",
    "            edge = 'left'\n",
    "    if len(l) % 2:\n",
    "        raise AssertionError()\n",
    "    g = iter(l)\n",
    "    return name, list(zip(g, g))\n",
    "horizontal_extents = {name: l for name, l in it.starmap(fn, data.items())}\n",
    "{k: ' '.join(map(str, v)) for k, v in horizontal_extents.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the letter images for each Hero.\n",
    "def fn(name):\n",
    "    def fn(letter):\n",
    "        # Due to taking additional one-pixel margins to the left and right, ensure the left- and\n",
    "        # right-most columns have values no greater than the columns next to them.\n",
    "        letter[:, 0] = np.min(letter[:, :2], axis=1)\n",
    "        letter[:, -1] = np.min(letter[:, -2:], axis=1)\n",
    "        return letter\n",
    "    image = data[name]\n",
    "    letters = [fn(image[:, left:right]) for left, right in horizontal_extents[name]]\n",
    "    return letters\n",
    "hero_letter_images = {name: fn(name) for name in horizontal_extents}\n",
    "max_width = max(np.hstack(letters).shape[1] for letters in hero_letter_images.values())\n",
    "l = [np.hstack(letters + [np.zeros((letters[0].shape[0], max_width - np.hstack(letters).shape[1]))]) for letters in hero_letter_images.values()]\n",
    "show_and_wait(np.vstack(l))\n",
    "cv2.destroyAllWindows()\n",
    "{k: ' '.join([str(i.shape) for i in v]) for k, v in hero_letter_images.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of letters to tuples of letter images.\n",
    "def fn(k, v):\n",
    "    g = (c.upper() for c in k if c != ' ')\n",
    "    #return zip(g, [type(v) for v in v])\n",
    "    return zip(g, v)\n",
    "l = sorted(it.chain.from_iterable(fn(k, v) for k, v in hero_letter_images.items()), key=lambda t: t[0])\n",
    "g = it.groupby(l, lambda t: t[0])\n",
    "letter_images = {c: [v for _, v in g] for c, g in g}\n",
    "{c: [type(v) for v in l] for c, l in letter_images.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct and display some random text.\n",
    "image = next(iter(data.values()))[0]\n",
    "dtype, height, width = image.dtype, *image.shape\n",
    "def make_letter():\n",
    "    file_title, extents = random.choice(tuple(selected_extents.items()))\n",
    "    left, right = random.choice(extents)\n",
    "    image = random.choice(data[file_title])\n",
    "    image = cv2.threshold(image, 0, 0, cv2.THRESH_TOZERO | cv2.THRESH_OTSU)[1]\n",
    "    image = image[:, left:right]\n",
    "    return image\n",
    "def make_space():\n",
    "    width = random.randint(0, 1) if random.random() < .8 else random.randint(7, 8)\n",
    "    image = np.zeros((height, width), dtype=dtype)\n",
    "    return image\n",
    "def fn():\n",
    "    a = (make_letter() for _ in it.repeat(None))\n",
    "    b = (make_space() for _ in it.repeat(None))\n",
    "    g = it.chain.from_iterable(zip(a, b))\n",
    "    n = random.randint(2, 19) * 2 - 1\n",
    "    g = (image for _, image in zip(range(n), g))\n",
    "    image = np.hstack(list(g))\n",
    "    if image.shape[1] < width:\n",
    "        image = np.hstack([image, np.zeros((height, width - image.shape[1]))])\n",
    "    else:\n",
    "        image = image[:, :width]\n",
    "    return image\n",
    "show_and_wait(np.vstack([fn() for _ in range(9)]))\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn():\n",
    "    file_path = r\"D:\\Dota 2\\Heroes\\Pickles\\letter_image_dict.pickle\"\n",
    "    if os.access(file_path, os.F_OK):\n",
    "        # Load the previously saved dictionary.\n",
    "        with open(file_path, 'rb') as fin:\n",
    "            d = pickle.load(fin)\n",
    "    else:\n",
    "        # Create a dictionary of letters to images for each extent extracted from each image in the data dictionary.\n",
    "        d = collections.defaultdict(list)\n",
    "        for file_title, images in data.items():\n",
    "            file_extents = selected_extents[file_title]\n",
    "            letters = [c for c in file_title if c != '_']\n",
    "            for (left, right), letter in zip(file_extents, letters):\n",
    "                for image in images:\n",
    "                    image = cv2.threshold(image, 0, 0, cv2.THRESH_TOZERO | cv2.THRESH_OTSU)[1]\n",
    "                    image = image[:, left:right]\n",
    "                    d[letter.upper()].append(image)\n",
    "        # Save that dictionary.\n",
    "        with open(file_path, 'wb') as fout:\n",
    "            pickle.dump(letter_images, fout)\n",
    "    return d\n",
    "letter_images = fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(letter_images), *letter_images)\n",
    "l = [(k, len(v)) for k, v in letter_images.items()]\n",
    "print(sum(n for _, n in l))\n",
    "print(*l, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display examples of each letter.\n",
    "def display_examples(d):\n",
    "    def fn(c):\n",
    "        width = 11 + max(np.hstack(list(g)).shape[1] for g in grouper(random.sample(d[c], k=2000), 50))\n",
    "        def fn(g):\n",
    "            image = np.hstack(list(g))\n",
    "            image = np.hstack([image, np.zeros((image.shape[0], width - image.shape[1]))])\n",
    "            return image\n",
    "        return show_and_wait(np.vstack([fn(g) for g in grouper(random.sample(d[c], k=2000), 50)]))\n",
    "    g = map(fn, sorted(d))\n",
    "    _ = list(it.takewhile(lambda c: c != 'q', g))\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_examples(letter_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a file that multiple processes can partially load.\n",
    "file_path = r\"D:\\Dota 2\\Heroes\\Pickles\\letter_images.pickle\"\n",
    "if not os.access(file_path, os.F_OK):\n",
    "    with open(file_path, 'wb') as fout:\n",
    "        # Write a dictionary of letter image counts.\n",
    "        pickle.dump({k: len(v) for k, v, in letter_images.items()}, fout)\n",
    "        # Write each letter's images in lexical order.\n",
    "        for k, v in sorted(letter_images.items()):\n",
    "            print(k, len(v))\n",
    "            pickle.dump(tuple(v), fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test partial loading.\n",
    "def fn():\n",
    "    with open(file_path, 'rb') as fin:\n",
    "        # Read the letter image count dictionary.\n",
    "        d = pickle.load(fin)\n",
    "        # Read a fraction of the images for each letter.\n",
    "        d = {k: random.sample(pickle.load(fin), k=9999) for k in sorted(d)}\n",
    "    return d\n",
    "sampled_letter_images = fn()\n",
    "[(k, len(v)) for k, v in sampled_letter_images.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display examples of each letter.\n",
    "display_examples(sampled_letter_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of letters to images for each extent extracted from each image in each video file.\n",
    "# Distinguish between large and small letter renderings by using an upper-case letter for the large ones and\n",
    "# a lower-case letter for the small ones.\n",
    "small_letters = {\n",
    "    'ancient_apparition',\n",
    "    'centaur_warrunner',\n",
    "    'keeper_of_the_light',\n",
    "    'outworld_devourer',\n",
    "}\n",
    "def fn():\n",
    "    file_path = r\"D:\\Dota 2\\Heroes\\Pickles\\sized_letter_images.pickle\"\n",
    "    if os.access(file_path, os.F_OK):\n",
    "        with open(file_path, 'rb') as fin:\n",
    "            # Read the dictionary of letter image counts.\n",
    "            d = pickle.load(fin)\n",
    "            # Read each letter's images in lexical order.\n",
    "            for k in sorted(d):\n",
    "                d[k] = pickle.load(fin)\n",
    "    else:\n",
    "        # Create a file that multiple processes can partially load.\n",
    "        d = collections.defaultdict(list)\n",
    "        for file_title, images in data.items():\n",
    "            file_extents = selected_extents[file_title]\n",
    "            letters = [c if file_title in small_letters else c.upper() for c in file_title if c != '_']\n",
    "            for (left, right), letter in zip(file_extents, letters):\n",
    "                for image in images:\n",
    "                    image = cv2.threshold(image, 0, 0, cv2.THRESH_TOZERO | cv2.THRESH_OTSU)[1]\n",
    "                    image = image[:, left:right]\n",
    "                    d[letter].append(image)\n",
    "        with open(file_path, 'wb') as fout:\n",
    "            # Write a dictionary of letter image counts.\n",
    "            pickle.dump({k: len(v) for k, v, in d.items()}, fout)\n",
    "            # Write each letter's images in lexical order.\n",
    "            for k, v in sorted(d.items()):\n",
    "                print(k, len(v))\n",
    "                pickle.dump(tuple(v), fout)\n",
    "    return d\n",
    "sized_letter_images = fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*sorted(sized_letter_images))\n",
    "def fn(fn):\n",
    "    all_letters = {fn(chr(i)) for i in range(ord('A'), ord('Z') + 1)}\n",
    "    given_letters = {c for c in sized_letter_images if c == fn(c)}\n",
    "    missing_letters = all_letters - given_letters\n",
    "    print('missing', len(missing_letters), sorted(missing_letters))\n",
    "fn(str.upper)\n",
    "fn(str.lower)\n",
    "[(k, len(v)) for k, v in sorted(sized_letter_images.items())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display examples of each letter.\n",
    "display_examples(sized_letter_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the minimum number of zeros to include images.\n",
    "class Finder:\n",
    "    def __init__(self, images):\n",
    "        self.__nzeros = [image.sum() for image in images]\n",
    "        self.__len = op.mul(*images[0].shape[:2])\n",
    "        self.__n = len(images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        l = [nzeros for nzeros in self.__nzeros if nzeros >= index]\n",
    "        return 1 if len(l) * 10 < self.__n else -1\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.__len\n",
    "\n",
    "def fn(file_title, file_images):\n",
    "    print(file_title)\n",
    "    file_images = [cv2.threshold(i, 0, 0, cv2.THRESH_TOZERO | cv2.THRESH_OTSU)[1] == 0 for i in file_images]\n",
    "    letters = [c if file_title in small_letters else c.upper() for c in file_title if c != '_']\n",
    "    def fn(t):\n",
    "        index, horizontal_extent = t\n",
    "        left, right = horizontal_extent\n",
    "        #letter_images = [image[4:-3, left:right] for image in file_images]\n",
    "        #minimum_nzero = (file_images[0].shape[0] - 7) * -op.sub(*selected_extents[file_title][1]) // 2\n",
    "        letter_images = [image[:, left:right] for image in file_images]\n",
    "        minimum_nzero = bisect.bisect_left(Finder(letter_images), 0)\n",
    "        return index, minimum_nzero - 1\n",
    "    file_extents = selected_extents[file_title]\n",
    "    d = dict(map(fn, enumerate(file_extents)))\n",
    "    return d\n",
    "#minimum_nzeros = {k: fn(k, v) for k, v in data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the minimum numbers of zeros created above.\n",
    "minimum_nzeros = {\n",
    "    'ancient_apparition': {0: 86, 1: 100, 2: 87, 3: 43, 4: 56, 5: 82, 6: 87, 7: 101, 8: 69, 9: 70, 10: 101, 11: 82, 12: 43, 13: 87, 14: 43, 15: 97, 16: 82},\n",
    "    'anti-mage': {0: 114, 1: 94, 2: 101, 3: 42, 4: 62, 5: 106, 6: 111, 7: 96, 8: 68},\n",
    "    'broodmother': {0: 79, 1: 79, 2: 108, 3: 110, 4: 90, 5: 106, 6: 108, 7: 101, 8: 96, 9: 68, 10: 91},\n",
    "    'centaur_warrunner': {0: 87, 1: 69, 2: 99, 3: 87, 4: 70, 5: 85, 6: 83, 7: 127, 8: 70, 9: 67, 10: 67, 11: 83, 12: 82, 13: 84, 14: 69, 15: 83},\n",
    "    'clinkz': {0: 99, 1: 82, 2: 52, 3: 94, 4: 95, 5: 82},\n",
    "    'io': {0: 42, 1: 108},\n",
    "    'juggernaut': {0: 72, 1: 96, 2: 96, 3: 98, 4: 79, 5: 79, 6: 94, 7: 114, 8: 94, 9: 101},\n",
    "    'keeper_of_the_light': {0: 85, 1: 69, 2: 72, 3: 69, 4: 71, 5: 82, 6: 95, 7: 70, 8: 88, 9: 84, 10: 72, 11: 73, 12: 43, 13: 87, 14: 84, 15: 88},\n",
    "    \"nature's_prophet\": {0: 94, 1: 98, 2: 85, 3: 80, 4: 92, 5: 79, 6: 46, 7: 83, 8: 77, 9: 80, 10: 110, 11: 83, 12: 94, 13: 79, 14: 101},\n",
    "    'nyx_assassin': {0: 93, 1: 100, 2: 95, 3: 97, 4: 84, 5: 84, 6: 111, 7: 81, 8: 81, 9: 52, 10: 94},\n",
    "    'outworld_devourer': {0: 99, 1: 83, 2: 87, 3: 115, 4: 97, 5: 69, 6: 70, 7: 81, 8: 81, 9: 68, 10: 88, 11: 99, 12: 83, 13: 83, 14: 70, 15: 69},\n",
    "    'queen_of_pain': {0: 134, 1: 79, 2: 79, 3: 67, 4: 93, 5: 123, 6: 81, 7: 82, 8: 95, 9: 52, 10: 94},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the images resulting from applying the minimum numbers of zeros.\n",
    "def fn(file_title, index, minimum_nzeros):\n",
    "    g = (image for image in data[file_title])\n",
    "    g = (cv2.threshold(image, 0, 0, cv2.THRESH_TOZERO | cv2.THRESH_OTSU)[1] for image in g)\n",
    "    left, right = selected_extents[file_title][index]\n",
    "    g = (image[:, left:right] for image in g)\n",
    "    g = (image for image in g if minimum_nzeros * 1.1 > (image == 0).sum() >= minimum_nzeros)\n",
    "    g = next(grouper(g, 1200))\n",
    "    image = np.vstack([np.hstack(list(g)) for g in grouper(g, 60)])\n",
    "    #print(file_title, index, minimum_nzeros, [c for c in file_title if c != '_'][index].upper())\n",
    "    return show_and_wait(image)\n",
    "g = ((s, i, m) for s in file_titles for i, m in sorted(minimum_nzeros[s].items()))\n",
    "list(it.takewhile(lambda t: fn(*t) != 'q', g))\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of clean letters to images for each extent extracted from each image in each video file.\n",
    "# Distinguish between large and small letter renderings by using an upper-case letter for the large ones and\n",
    "# a lower-case letter for the small ones.\n",
    "def fn():\n",
    "    file_path = r\"D:\\Dota 2\\Heroes\\Pickles\\clean_letter_images.pickle\"\n",
    "    if os.access(file_path, os.F_OK):\n",
    "        with open(file_path, 'rb') as fin:\n",
    "            # Read the dictionary of letter image counts.\n",
    "            d = pickle.load(fin)\n",
    "            # Read each letter's images in lexical order.\n",
    "            for k in sorted(d):\n",
    "                d[k] = pickle.load(fin)\n",
    "        print({k: len(v) for k, v, in d.items()})\n",
    "    else:\n",
    "        # Create a file that multiple processes can partially load.\n",
    "        d = collections.defaultdict(list)\n",
    "        for file_title, images in data.items():\n",
    "            file_minimum_nzeros = minimum_nzeros[file_title]\n",
    "            l = [cv2.threshold(image, 0, 0, cv2.THRESH_TOZERO | cv2.THRESH_OTSU)[1] for image in images]\n",
    "            file_extents = selected_extents[file_title]\n",
    "            letters = [c if file_title in small_letters else c.upper() for c in file_title if c != '_']\n",
    "            for (left, right), (index, letter) in zip(file_extents, enumerate(letters)):\n",
    "                m = file_minimum_nzeros[index]\n",
    "                for image in l:\n",
    "                    image = image[:, left:right]\n",
    "                    if m * 1.1 > (image == 0).sum() >= m:\n",
    "                        d[letter].append(image)\n",
    "        with open(file_path, 'wb') as fout:\n",
    "            # Write a dictionary of letter image counts.\n",
    "            pickle.dump({k: len(v) for k, v, in d.items()}, fout)\n",
    "            # Write each letter's images in lexical order.\n",
    "            for k, v in sorted(d.items()):\n",
    "                print(k, len(v))\n",
    "                pickle.dump(tuple(v), fout)\n",
    "    return d\n",
    "clean_letter_images = fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect clean letter images.\n",
    "def fn():\n",
    "    for letter, images in clean_letter_images.items():\n",
    "        image = np.vstack([np.hstack(list(g)) for g in grouper(images[:1200], 60)])\n",
    "        print(letter)\n",
    "        if show_and_wait(image) == 'q':\n",
    "            break\n",
    "#fn()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_margin = 5\n",
    "def put_text(background: np.ndarray, text: str, letter_images):\n",
    "    image = background.copy()\n",
    "\n",
    "    # Construct the image of the text.\n",
    "    dtype, height, width = image.dtype, *image.shape\n",
    "    def make_letter(letter):\n",
    "        image = random.choice(letter_images[letter])\n",
    "        return image\n",
    "    def make_space():\n",
    "        # Randomly add to the text about one space for every five characters.\n",
    "        width = random.randint(7, 8) if random.random() < .167 else random.randint(0, 1)\n",
    "        image = np.zeros((height, width), dtype)\n",
    "        return image\n",
    "    def fn():\n",
    "        a = map(make_letter, text)\n",
    "        b = (make_space() for _ in text)\n",
    "        g = it.chain.from_iterable(zip(a, b))\n",
    "        image = np.hstack(list(g)[:-1])\n",
    "        if image.shape[1] < width - 2 * horizontal_margin:\n",
    "            # Select a random position for the rendered text in the background.\n",
    "            left = random.randrange(horizontal_margin, width - horizontal_margin - image.shape[1])\n",
    "            right = width - image.shape[1] - left\n",
    "            return np.hstack([np.zeros((height, left), dtype), image, np.zeros((height, right), dtype)])\n",
    "    text_image = fn()\n",
    "    if text_image is None:\n",
    "        # The text renders too wide.  Try again.\n",
    "        return\n",
    "\n",
    "    # Apply the rendered greyscale text to the background.\n",
    "    image = image * (text_image == 0) + text_image\n",
    "    image = cv2.threshold(image, 0, 0, cv2.THRESH_TOZERO | cv2.THRESH_OTSU)[1]\n",
    "    image = image * (text_image == 0) + text_image\n",
    "\n",
    "    # Add the removed dimension.\n",
    "    image = image[:, :, np.newaxis]\n",
    "\n",
    "    return image\n",
    "image = put_text(np.zeros((16, 120), np.uint8), 'ACDEF', clean_letter_images)\n",
    "show_and_wait(image)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the code is archived and not used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 1200 of each letter.\n",
    "# Manually select ranges of images to exclude.\n",
    "nimages = 1200\n",
    "ncolumns = 60\n",
    "window_name = 'tesst'\n",
    "cv2.namedWindow(window_name, cv2.WINDOW_NORMAL | cv2.WINDOW_GUI_EXPANDED)\n",
    "def fn(file_title, horizontal_extent):\n",
    "    images = data[file_title]\n",
    "    indices = list(range(nimages))\n",
    "    left, right = horizontal_extent\n",
    "    def fn():\n",
    "        g = (cv2.threshold(images[i], 0, 0, cv2.THRESH_TOZERO | cv2.THRESH_OTSU)[1][:, left:right] for i in indices)\n",
    "        g = grouper(g, ncolumns)\n",
    "        return np.vstack([np.hstack(list(g)) for g in g])\n",
    "    initial_index = []\n",
    "    height, width = images[0].shape[0], right - left\n",
    "    def handle_mouse_event(event, x, y, *_):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            initial_index.clear()\n",
    "            initial_index.append((y // height) * ncolumns + x // width)\n",
    "        elif event == cv2.EVENT_RBUTTONDOWN:\n",
    "            index = (y // height) * ncolumns + x // width\n",
    "            begin, end = initial_index[0] if initial_index else index, index + 1\n",
    "            del indices[begin:end]\n",
    "            begin = indices[-1] + 1\n",
    "            end = begin + nimages - len(indices)\n",
    "            indices.extend(range(begin, end))\n",
    "            cv2.imshow(window_name, fn())\n",
    "            initial_index.clear()\n",
    "    cv2.setMouseCallback(window_name, handle_mouse_event)\n",
    "    show_and_wait(fn())\n",
    "    return indices\n",
    "#fn('io', selected_extents['io'][1])\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 1200 of each letter.\n",
    "# Manually select the minimum number of zeros to include images.\n",
    "nimages = 1200\n",
    "ncolumns = 60\n",
    "window_name = 'tesst'\n",
    "cv2.namedWindow(window_name, cv2.WINDOW_NORMAL | cv2.WINDOW_GUI_EXPANDED)\n",
    "def fn(file_title, horizontal_extent):\n",
    "    images = data[file_title]\n",
    "    minimum_nzero = images[0].shape[0] * -op.sub(*selected_extents[file_title][1]) // 2\n",
    "    left, right = horizontal_extent\n",
    "    def fn():\n",
    "        l = random.sample(images, len(images))\n",
    "        g = (cv2.threshold(image, 0, 0, cv2.THRESH_TOZERO | cv2.THRESH_OTSU)[1] for image in l)\n",
    "        g = (image[:, left:right] for image in g)\n",
    "        return [image for image in g if (image == 0).sum() >= minimum_nzero]\n",
    "    while True:\n",
    "        l = fn()\n",
    "        if len(l) < nimages:\n",
    "            image = np.zeros([1, 1], dtype=images[0].dtype)\n",
    "        else:\n",
    "            image = np.vstack([np.hstack(list(g)) for g in grouper(l[:nimages], ncolumns)])\n",
    "        ch = show_and_wait(image)\n",
    "        if ch == '-':\n",
    "            minimum_nzero -= 1\n",
    "        elif ch == '+':\n",
    "            minimum_nzero += 1\n",
    "        elif ch == '/':\n",
    "            minimum_nzero -= 10\n",
    "        elif ch == '*':\n",
    "            minimum_nzero += 10\n",
    "        elif ch == 'p':\n",
    "            print(minimum_nzero, len(l))\n",
    "        elif ch == 'q':\n",
    "            return minimum_nzero, len(fn())\n",
    "#print(fn('io', selected_extents['io'][1]))\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
