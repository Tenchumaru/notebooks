{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "import collections\n",
    "import cv2\n",
    "import itertools as it\n",
    "import numpy as np\n",
    "import operator as op\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "def show_and_wait(image):\n",
    "    cv2.imshow('tesst', image)\n",
    "    cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_titles = [\n",
    "    'Ancient Apparition',\n",
    "    'Anti-Mage',\n",
    "    'Broodmother',\n",
    "    'Centaur Warrunner',\n",
    "    'Clinkz',\n",
    "    'Io',\n",
    "    'Juggernaut',\n",
    "    'Keeper of the Light',\n",
    "    \"Nature's Prophet\",\n",
    "    'Nyx Assassin',\n",
    "    'Outworld Devourer',\n",
    "    'Queen of Pain',\n",
    "]\n",
    "s = {c.lower() for c, _ in it.groupby(sorted(it.chain.from_iterable(file_titles)))}\n",
    "print(len(file_titles), ''.join(sorted(s)), len(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a process for determining the letters in the images.\n",
    "\n",
    "1. Create a mean image for each hero.  A mean image is the mean of all available images for a hero.\n",
    "1. Find the vertical extents of the text in the images.  This is not the vertical extents of the letters.  Adjust for the \"Q\" descender in \"Queen of Pain\".\n",
    "1. Crop the images to those vertical extents for the rest of the process.\n",
    "1. Find the horizontal extents of the text in the images.  This is not the horizontal extents of the letters.  This is the left-most edge of the left-most letter and the right-most edge of the right-most letter.\n",
    "1. Crop the images to those horizontal extents for the rest of the process.\n",
    "1. Find the horizontal extents of the letters.  Note that there are three instances of letters having overlapping bright pixels due to kerning:  \"TA\" and \"WA\" in \"CENTAUR WARRUNNER\" and \"AT\" in \"NATURE'S PROPHET\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mean image for each hero.  A mean image is the mean of all available images for a hero.\n",
    "directory_path = r'F:\\Dota 2\\Heroes\\Pictures'\n",
    "def fn(file_title):\n",
    "    def fn(file_name: str):\n",
    "        # Read the image.\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        image = cv2.imread(file_path)\n",
    "\n",
    "        # Color data adds no value to this methodology.\n",
    "        # Take the color channel with the lowest value.  This changes\n",
    "        # the shape of the image from (60, 160, 3) to (60, 160).\n",
    "        return image[:, :, np.argmin(np.sum(image.astype(np.float32), axis=(0, 1)))]\n",
    "\n",
    "    # Read and grey all files in the Pictures directory for the given file title.\n",
    "    _, _, file_names = next(os.walk(directory_path))\n",
    "    g = (file_name for file_name in file_names if file_name.startswith(file_title))\n",
    "    images = list(map(fn, g))\n",
    "\n",
    "    # Combine the list of two-dimensional tensors into a single three-dimensional tensor.\n",
    "    images = np.stack(images, axis=0)\n",
    "\n",
    "    # Compute the mean image.\n",
    "    mean = np.mean(images.astype(np.float32), axis=0) / 255\n",
    "\n",
    "    # Clean up the bottom edge.\n",
    "    mean[-1, :] = (mean[-2, :] + mean[0, :]) / 2\n",
    "    return mean\n",
    "    mean = fn(images)\n",
    "    return masking_factor, mean\n",
    "hero_mean_images = {s: fn(s) for s in file_titles}\n",
    "\n",
    "# Show the hero mean images.\n",
    "show_and_wait(np.vstack([i for i in hero_mean_images.values()]))\n",
    "cv2.destroyAllWindows()\n",
    "[(v.min(), v.mean(), v.max(), v.dtype, v.shape) for v in hero_mean_images.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the vertical extents of the text in the images.  This is not the vertical extents of the\n",
    "# letters.  Adjust for the \"Q\" descender in \"Queen of Pain\".\n",
    "\n",
    "# Find the maximum value of each row of each hero mean image.\n",
    "d = {s: np.max(hero_mean_images[s], axis=1) for s in file_titles}\n",
    "\n",
    "# Those that fall below the mean for the column are not in a letter.  These are the vertical\n",
    "# extents.  I need these for the mean image since it's not black outside of the letters.\n",
    "d = {k: v < np.mean(v) for k, v in d.items()}\n",
    "d = {k: [i + 1 for i, b in enumerate(v[:-1] ^ v[1:]) if b] for k, v in d.items()}\n",
    "\n",
    "# Adjust the vertical extents to account for the dark borders around the letters.  I want to\n",
    "# include those as part of the letters.  The \"Q\" of \"Queen of Pain\" needs special handling because\n",
    "# it has a descender.  For now, I'll ignore the \"Q\".\n",
    "d = {k: (a - 1, b + (1 if k == 'Queen of Pain' else 2)) for k, (a, b) in d.items()}\n",
    "hero_vertical_extents = d\n",
    "\n",
    "# Considering the standard deviations of the values in each row as a different means of obtaining\n",
    "# the vertical extents results in the same extents as those obtained here.\n",
    "\n",
    "# Show those values as white pixels to the right of the letters.\n",
    "def fn(image, t):\n",
    "    top, bottom = t\n",
    "    image = image.copy()\n",
    "    right = image.shape[1] // 2\n",
    "    image[:top, right:] = 1.0\n",
    "    image[bottom:, right:] = 1.0\n",
    "    return image\n",
    "image = np.vstack(list(it.starmap(fn, zip(hero_mean_images.values(), d.values()))))\n",
    "show_and_wait(image)\n",
    "cv2.destroyAllWindows()\n",
    "{k: (16*m+v[0],16*m+v[1],''if len(v)==2 else'not 2') for m, (k, v) in enumerate(d.items())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop the images to those vertical extents for the rest of the process.  This does not adversely\n",
    "# affect \"Queen of Pain\" since the descender of its \"Q\" is still visible.\n",
    "vertically_cropped_hero_mean_images = {k: v[hero_vertical_extents[k][0]:hero_vertical_extents[k][1], :] for k, v in hero_mean_images.items()}\n",
    "image = np.vstack(list(vertically_cropped_hero_mean_images.values()))\n",
    "show_and_wait(image)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the horizontal extents of the text in the images.  This is not the horizontal extents of\n",
    "# the letters.  This is the left-most edge of the left-most letter and the right-most edge of the\n",
    "# right-most letter.\n",
    "\n",
    "# Look for significant variations along the horizontal axis.  With the current limit, it also\n",
    "# captures the boundaries of the words.\n",
    "d = {k: np.std(v, axis=0) > 0.011 for k, v in vertically_cropped_hero_mean_images.items()}\n",
    "def fn(name, bools):\n",
    "    image = vertically_cropped_hero_mean_images[name].copy()\n",
    "    for i, b in enumerate(bools):\n",
    "        image[-1, i] = 1.0 if b else 0.0\n",
    "    return image\n",
    "show_and_wait(np.vstack([fn(k, v) for k, v in d.items()]))\n",
    "cv2.destroyAllWindows()\n",
    "def fn(bools):\n",
    "    g = it.dropwhile(lambda t: not t[1], enumerate(bools))\n",
    "    left = next(g)[0]\n",
    "    g = it.dropwhile(lambda t: not t[1], enumerate(reversed(bools)))\n",
    "    right = len(bools) - next(g)[0]\n",
    "    return left, right\n",
    "d = {k: fn(v) for k, v in d.items()}\n",
    "hero_horizontal_extents = d\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop the images to those horizontal extents for the rest of the process.\n",
    "fully_cropped_hero_mean_images = {k: v[:, hero_horizontal_extents[k][0]:hero_horizontal_extents[k][1]] for k, v in vertically_cropped_hero_mean_images.items()}\n",
    "max_width = max(v.shape[1] for v in fully_cropped_hero_mean_images.values())\n",
    "image = np.vstack([np.hstack([v, np.zeros((v.shape[0], max_width - v.shape[1]))]) for v in fully_cropped_hero_mean_images.values()])\n",
    "show_and_wait(image)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration\n",
    "\n",
    "# Find the boundaries between the letters.  Note that there are three instances of letters having\n",
    "# overlapping bright pixels due to kerning:  \"TA\" and \"WA\" in \"CENTAUR WARRUNNER\" and \"AT\" in\n",
    "# \"NATURE'S PROPHET\".\n",
    "\n",
    "# Find the maximum of each column for each hero's fully-cropped mean image.\n",
    "d = {k: [np.max(v[:, i]) for i in range(v.shape[1])] for k, v in fully_cropped_hero_mean_images.items()}\n",
    "hero_maxima = d\n",
    "\n",
    "# Assume maximum values below a threshold represent the spaces between the letters.\n",
    "d = {k: [v < .312 for v in v] for k, v in hero_maxima.items()}\n",
    "\n",
    "# Ignore maxima that occur at the beginning or end of their images.\n",
    "d = {k: list(it.dropwhile(lambda v: v, v)) for k, v in d.items()}\n",
    "d = {k: list(reversed(list(it.dropwhile(lambda v: v, reversed(v))))) for k, v in d.items()}\n",
    "hero_spaces = d\n",
    "\n",
    "# Show those values as white pixels below the letters.\n",
    "def fn(image, l):\n",
    "    image = image.copy()\n",
    "    for i, b in enumerate(l):\n",
    "        if b:\n",
    "            image[-1:, i] = 1.0\n",
    "    return image\n",
    "g = (it.starmap(fn, zip(fully_cropped_hero_mean_images.values(), d.values())))\n",
    "show_and_wait(np.vstack([np.hstack([v, np.zeros((v.shape[0], max_width - v.shape[1]))]) for v in g]))\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Determine the horizontal letter extents.\n",
    "def fn(name, l):\n",
    "    l = [a ^ b for a, b in it.pairwise(l)]\n",
    "    l = [0] + [i + 1 for i, b in enumerate(l) if b] + [fully_cropped_hero_mean_images[name].shape[1]]\n",
    "    if len(l) % 2:\n",
    "        raise AssertionError()\n",
    "    for i in range(1, len(l) - 1, 2):\n",
    "        j = i + 1\n",
    "        diff = l[j] - l[i]\n",
    "        if diff:\n",
    "            l[i] += 2 if 2 < diff < 4 else 1\n",
    "            l[j] -= 1 if diff > 1 else 0\n",
    "            #if l[i] != l[j]:\n",
    "             #   raise AssertionError(f'{l[i]}!={l[j]}')\n",
    "    g = iter(l)\n",
    "    g = zip(g, g)\n",
    "    return list(g)\n",
    "horizontal_letter_extents = {k: fn(k, v) for k, v in hero_spaces.items()}\n",
    "\n",
    "# TODO:  there's a problem with these values.\n",
    "\n",
    "# Add extents for the kerned pairs.\n",
    "l = horizontal_letter_extents['Centaur Warrunner']\n",
    "l = l[:3] + [(18, 23), (23, 30)] + l[4:6] + [(44, 52), (52, 59)] + l[7:]\n",
    "horizontal_letter_extents['Centaur Warrunner'] = l\n",
    "l = horizontal_letter_extents[\"Nature's Prophet\"]\n",
    "l = l[:1] + [(6, 15), (15, 21)] + l[2:]\n",
    "horizontal_letter_extents[\"Nature's Prophet\"] = l\n",
    "horizontal_letter_extents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration 2\n",
    "\n",
    "# Start with the upper-left pixel of each image.\n",
    "# Count the number of crossings over that pixel's value for each image's brightness profile.\n",
    "def fn(name, image):\n",
    "    # Compute the number of non-space characters in the name.\n",
    "    n = len([c for c in name if c != ' '])\n",
    "\n",
    "    # Compute the max along the vertical axis to get a brightness profile\n",
    "    brightness = np.max(image, axis=0)\n",
    "\n",
    "    # Determine the crossings for nine values between the top-left pixel and the maximum value.\n",
    "    top_left_pixel = image[0, 0]\n",
    "    maximum = np.max(image)\n",
    "    for i in range(9):\n",
    "        bools = brightness < top_left_pixel + (maximum - top_left_pixel) * i / 8\n",
    "        crossings = [bools[i] ^ bools[i + 1] for i in range(len(bools) - 1)]\n",
    "        l = [i + 1 for i, b in enumerate(crossings) if b]\n",
    "        if len(l) == 2 * n:\n",
    "            # This is the desired number of crossings.  Return the indices of those crossings.\n",
    "            g = iter(l)\n",
    "            l = [list(t) for t in zip(g, g)]\n",
    "\n",
    "            # Extend letter horizontal extents for letters that are less than four pixels apart.\n",
    "            if False:\n",
    "                for i in range(len(l) - 1):\n",
    "                    diff = l[i + 1][0] - l[i][1]\n",
    "                    if diff in [1, 2]:\n",
    "                        l[i][1] += 1\n",
    "                        l[i + 1][0] -= 1\n",
    "                    elif diff == 3:\n",
    "                        l[i][1] += 2\n",
    "                        l[i + 1][0] -= 1\n",
    "            elif False:\n",
    "                # Extend outwards while the mean values decrease by at least a limit.\n",
    "                mean = np.mean(image, axis=0)\n",
    "                limit = 1/255\n",
    "                for extents in l:\n",
    "                    while extents[0] and mean[extents[0] - 1] + limit < mean[extents[0]]:\n",
    "                        extents[0] -= 1\n",
    "            else:\n",
    "                # Extend the left value of all extents by one the right value of all extents by up\n",
    "                # to two.\n",
    "                for i, extents in enumerate(l):\n",
    "                    extents[0] -= 1\n",
    "                    #extents[1] += 2 if\n",
    "\n",
    "            return l\n",
    "\n",
    "hero_letter_boundaries = {k: fn(k, v) for k, v in fully_cropped_hero_mean_images.items()}\n",
    "d = {k: (len([c for c in k if c != ' ']), v) for k, v in hero_letter_boundaries.items()}\n",
    "print(*d.items(), sep='\\n')\n",
    "\n",
    "def fn(name, extents):\n",
    "    image = np.zeros((2, fully_cropped_hero_mean_images[name].shape[1]))\n",
    "    for i, (left, right) in enumerate(extents):\n",
    "        image[i % 2, left:right] = 1.0\n",
    "    return np.vstack([fully_cropped_hero_mean_images[name], image])\n",
    "g = (fn(k, v) for k, v in hero_letter_boundaries.items())\n",
    "show_and_wait(np.vstack([np.hstack([v, np.zeros((v.shape[0], max_width - v.shape[1]))]) for v in g]))\n",
    "cv2.destroyAllWindows()\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Find the boundaries between the letters.  Note there are three instances of letters having\n",
    "# overlapping bright pixels due to kerning:  \"TA\" and \"WA\" in \"CENTAUR WARRUNNER\" and \"AT\" in\n",
    "# \"NATURE'S PROPHET\".\n",
    "\n",
    "# Find the horizontal extent of each letter in each image.\n",
    "def fn(name, image):\n",
    "    # Count the number of non-space characters.\n",
    "    n = len([c for c in name if c != ' '])\n",
    "\n",
    "    # Compute the max along the vertical axis to get a brightness profile\n",
    "    image = np.max(image, axis=0)\n",
    "\n",
    "    # Loop by a small increment and determine the number of crossings across the limit.\n",
    "    max_limit = np.max(image)\n",
    "    g = (max_limit * i / 999 for i in range(1000))\n",
    "    def fn(limit):\n",
    "        a = image < limit\n",
    "        a = a[1:] ^ a[:-1]\n",
    "        return np.sum(a)\n",
    "    g = it.dropwhile(lambda t: t[1] != 2 * n, enumerate(map(fn, g)))\n",
    "    limit = max_limit * next(g)[0] / 999\n",
    "    print(name, limit)\n",
    "\n",
    "    # Collect the indices of where the image value crosses above then below the limit.\n",
    "    # These constitute the left and right edges of the letters.\n",
    "    edge = 'left'\n",
    "    l = []\n",
    "    for i, v in enumerate(image):\n",
    "        if edge == 'left' and v >= limit:\n",
    "            # Take a one-pixel margin to the left if available.\n",
    "            l.append(i - 1 if i else i)\n",
    "            edge = 'right'\n",
    "        elif edge == 'right' and v < limit:\n",
    "            # Take a one-pixel margin to the right.\n",
    "            l.append(i + 1)\n",
    "            edge = 'left'\n",
    "    if len(l) % 2:\n",
    "        raise AssertionError(f'{n} {name} {len(l)} {l}')\n",
    "    g = iter(l)\n",
    "    horizontal_extents = list(zip(g, g))\n",
    "\n",
    "    # If there is only a single pixel of space between two extents, add that pixel to the left one.\n",
    "    for i in range(len(horizontal_extents) - 1):\n",
    "        if horizontal_extents[i][1] + 1 == horizontal_extents[i + 1][0]:\n",
    "            horizontal_extents[i] = (horizontal_extents[i][0], horizontal_extents[i][1] + 1)\n",
    "\n",
    "    return name, horizontal_extents\n",
    "hero_letter_boundaries = {name: l for name, l in it.starmap(fn, fully_cropped_hero_mean_images.items())}\n",
    "def fn(name, extents):\n",
    "    image = np.zeros((2, fully_cropped_hero_mean_images[name].shape[1]))\n",
    "    for i, (left, right) in enumerate(extents):\n",
    "        image[i % 2, left:right] = 1.0\n",
    "    return np.vstack([fully_cropped_hero_mean_images[name], image])\n",
    "g = (fn(k, v) for k, v in hero_letter_boundaries.items())\n",
    "show_and_wait(np.vstack([np.hstack([v, np.zeros((v.shape[0], max_width - v.shape[1]))]) for v in g]))\n",
    "cv2.destroyAllWindows()\n",
    "{k: f'{\"\" if len([c for c in k if c != \" \"])==len(v)else \"unexpected \"}{\" \".join(map(str, v))}' for k, v in hero_letter_boundaries.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum value of each row of each hero mean image.\n",
    "d = {s: np.max(hero_mean_images[s], axis=1) for s in file_titles}\n",
    "\n",
    "# Those that fall below the mean for the column are not in a letter.  These are the vertical\n",
    "# extents.  I need these for the mean image since it's not black outside of the letters.\n",
    "d = {k: v < np.mean(v) for k, v in d.items()}\n",
    "d = {k: [i + 1 for i, b in enumerate(v[:-1] ^ v[1:]) if b] for k, v in d.items()}\n",
    "\n",
    "# Adjust the vertical extents to account for the dark borders around the letters.  I want to\n",
    "# include those as part of the letters.\n",
    "d = {k: (a - 1, b + 2) for k, (a, b) in d.items()}\n",
    "hero_vertical_extents = d\n",
    "\n",
    "# The 'Q' of 'Queen of Pain' needs special handling because it has a descender.  For now, I'll\n",
    "# ignore the 'Q'.\n",
    "t = hero_vertical_extents['Queen of Pain']\n",
    "hero_vertical_extents['Queen of Pain'] = (t[0], t[1] - 1)\n",
    "\n",
    "# Considering the standard deviations of the values in each row as a different means of obtaining\n",
    "# the vertical extents results in the same extents as those obtained here.\n",
    "\n",
    "# Show those values as white pixels to the right of the letters.\n",
    "def fn(image, t):\n",
    "    top, bottom = t\n",
    "    image = image.copy()\n",
    "    right = image.shape[1] // 2\n",
    "    image[:top, right:] = 1.0\n",
    "    image[bottom:, right:] = 1.0\n",
    "    return image\n",
    "image = np.vstack(list(it.starmap(fn, zip(hero_mean_images.values(), d.values()))))\n",
    "show_and_wait(image)\n",
    "cv2.destroyAllWindows()\n",
    "{k: (16*m+v[0],16*m+v[1],''if len(v)==2 else'not 2') for m, (k, v) in enumerate(d.items())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for significant variations along the horizontal axis taking the vertical extents into\n",
    "# account by ignoring pixels outside of those extents.\n",
    "d = {k: np.std(v[hero_vertical_extents[k][0]:hero_vertical_extents[k][1]], axis=0) > 0.01 for k, v in hero_mean_images.items()}\n",
    "def fn(name, bools):\n",
    "    image = hero_mean_images[name].copy()\n",
    "    for i, b in enumerate(bools):\n",
    "        image[-1, i] = 1.0 if b else 0.0\n",
    "    return image\n",
    "show_and_wait(np.vstack([fn(k, v) for k, v in d.items()]))\n",
    "cv2.destroyAllWindows()\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the letter images for each Hero.\n",
    "def fn(name):\n",
    "    def fn(letter):\n",
    "        # Due to taking additional one-pixel margins to the left and right, ensure the left- and\n",
    "        # right-most columns have values no greater than the columns next to them.\n",
    "        letter[:, 0] = np.min(letter[:, :2], axis=1)\n",
    "        letter[:, -1] = np.min(letter[:, -2:], axis=1)\n",
    "        return letter\n",
    "    image = data[name]\n",
    "    letters = [fn(image[:, left:right]) for left, right in hero_horizontal_extents[name]]\n",
    "    return letters\n",
    "hero_letter_images = {name: fn(name) for name in hero_horizontal_extents}\n",
    "max_width = max(np.hstack(letters).shape[1] for letters in hero_letter_images.values())\n",
    "l = [np.hstack(letters + [np.zeros((letters[0].shape[0], max_width - np.hstack(letters).shape[1]))]) for letters in hero_letter_images.values()]\n",
    "show_and_wait(np.vstack(l))\n",
    "cv2.destroyAllWindows()\n",
    "{k: ' '.join([str(i.shape) for i in v]) for k, v in hero_letter_images.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of letters to tuples of letter images.\n",
    "def fn(k, v):\n",
    "    g = (c.upper() for c in k if c != ' ')\n",
    "    #return zip(g, [type(v) for v in v])\n",
    "    return zip(g, v)\n",
    "l = sorted(it.chain.from_iterable(fn(k, v) for k, v in hero_letter_images.items()), key=lambda t: t[0])\n",
    "g = it.groupby(l, lambda t: t[0])\n",
    "letter_images = {c: [v for _, v in g] for c, g in g}\n",
    "{c: list(map(type, l)) for c, l in letter_images.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print how many there are of each letter image.\n",
    "print(len(letter_images), *letter_images)\n",
    "l = [(k, len(v)) for k, v in letter_images.items()]\n",
    "print(sum(n for _, n in l))\n",
    "print(*l, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider creating a mask from the pixels that are outside of two times the standard deviation of\n",
    "# the grey background of pixels in the second and third rows.  Do this for each image since their\n",
    "# grey backgrounds are different from each other.\n",
    "def fn(image):\n",
    "    mean, std = np.mean(image[2:4, :]), np.std(image[2:4, :])\n",
    "    image = np.abs(image - mean)\n",
    "    image = image > 3 * std\n",
    "    return 255 * image.astype(np.float32)\n",
    "d = {k: fn(v) for k, v in hero_mean_images.items()}\n",
    "image = np.vstack(list(d.values()))\n",
    "show_and_wait(image)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the code is archived and not used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a masking factor for each hero.  A masking factor is the stability of the pixels in an\n",
    "# image.  The more stable the pixel, the higher is the value of the masking factor for that pixel.\n",
    "# I tried using the variance instead of the standard deviation but it has too much noise.\n",
    "directory_path = r'F:\\Dota 2\\Heroes\\Pictures'\n",
    "def fn(file_title):\n",
    "    def fn(file_name: str):\n",
    "        # Read the image.\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        image = cv2.imread(file_path)\n",
    "\n",
    "        # Color data adds no value to this methodology.\n",
    "        # Take the color channel with the lowest value.  This changes\n",
    "        # the shape of the image from (60, 160, 3) to (60, 160).\n",
    "        return image[:, :, np.argmin(np.sum(image, axis=(0, 1)))]\n",
    "\n",
    "    # Read and process all files in the Pictures directory for the given file title.\n",
    "    _, _, file_names = next(os.walk(directory_path))\n",
    "    g = (file_name for file_name in file_names if file_name.startswith(file_title))\n",
    "    images = list(map(fn, g))\n",
    "\n",
    "    # Combine the list of two-dimensional tensors into a single three-dimensional tensor.\n",
    "    images = np.stack(images, axis=0)\n",
    "\n",
    "    # Determine the desired factor by scaling the range of standard deviations\n",
    "    # of the sum of all values in each image from [max, min] to [0, 1].\n",
    "    std = np.std(images, axis=0)\n",
    "    desired_factor = (std - np.max(std)) / (np.min(std) - np.max(std))\n",
    "\n",
    "    # Clean up the edges.\n",
    "    desired_factor[-1, :] = 0\n",
    "\n",
    "    # Apply a threshold to remove the background.\n",
    "    image = (desired_factor * 255).astype(np.uint8)\n",
    "    threshold, image = cv2.threshold(image, 0, 0, cv2.THRESH_TOZERO | cv2.THRESH_OTSU)\n",
    "    while np.any(image[:, :16]):\n",
    "        threshold *= 1.1\n",
    "        print('updating', file_title, 'to', threshold)\n",
    "        _, image = cv2.threshold(image, threshold, 0, cv2.THRESH_TOZERO)\n",
    "    desired_factor = image.astype(np.float32) / 255\n",
    "    return desired_factor\n",
    "\n",
    "data = {s: fn(s) for s in file_titles}\n",
    "\n",
    "show_and_wait(np.vstack(list(data.values())))\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the vertical extent of the text in each image.\n",
    "def fn(name, image):\n",
    "    a = image.astype(np.float32)\n",
    "    a = np.max(a[1:], axis=1) - np.max(a[:-1], axis=1)\n",
    "    return name, np.argmax(a) + 1, np.argmin(a) + 1\n",
    "hero_vertical_extents = {name: (top, bottom) for name, top, bottom in it.starmap(fn, data.items())}\n",
    "hero_vertical_extents\n",
    "# I don't need these since my masks are all black above and below the letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider the standard deviations of the values in each row.  That might provide a better idea of\n",
    "# the vertical extents.\n",
    "d= {k: np.std(v, axis=1) for k, v in hero_mean_images.items()}\n",
    "d = {k: v < 0.0125 for k, v in d.items()}\n",
    "d = {k: [i + 1 for i, b in enumerate(v[:-1] ^ v[1:]) if b] for k, v in d.items()}\n",
    "\n",
    "# Show those values as white pixels to the right of the letters.\n",
    "def fn(image, t):\n",
    "    top, bottom = t\n",
    "    image = image.copy()\n",
    "    right = image.shape[1] // 2\n",
    "    image[:top, right:] = 1.0\n",
    "    image[bottom:, right:] = 1.0\n",
    "    return image\n",
    "image = np.vstack(list(it.starmap(fn, zip(hero_mean_images.values(), d.values()))))\n",
    "show_and_wait(image)\n",
    "cv2.destroyAllWindows()\n",
    "{k: (16*m+v[0],16*m+v[1],''if len(v)==2 else'not 2') for m, (k, v) in enumerate(d.items())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a file that multiple processes can partially load.\n",
    "file_path = r\"D:\\Dota 2\\Heroes\\Pickles\\letter_images.pickle\"\n",
    "if not os.access(file_path, os.F_OK):\n",
    "    with open(file_path, 'wb') as fout:\n",
    "        # Write a dictionary of letter image counts.\n",
    "        pickle.dump({k: len(v) for k, v, in letter_images.items()}, fout)\n",
    "        # Write each letter's images in lexical order.\n",
    "        for k, v in sorted(letter_images.items()):\n",
    "            print(k, len(v))\n",
    "            pickle.dump(tuple(v), fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test partial loading.\n",
    "def fn():\n",
    "    with open(file_path, 'rb') as fin:\n",
    "        # Read the letter image count dictionary.\n",
    "        d = pickle.load(fin)\n",
    "        # Read a fraction of the images for each letter.\n",
    "        d = {k: random.sample(pickle.load(fin), k=9999) for k in sorted(d)}\n",
    "    return d\n",
    "sampled_letter_images = fn()\n",
    "[(k, len(v)) for k, v in sampled_letter_images.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of letters to images for each extent extracted from each image in each video file.\n",
    "# Distinguish between large and small letter renderings by using an upper-case letter for the large ones and\n",
    "# a lower-case letter for the small ones.\n",
    "small_letters = {\n",
    "    'ancient_apparition',\n",
    "    'centaur_warrunner',\n",
    "    'keeper_of_the_light',\n",
    "    'outworld_devourer',\n",
    "}\n",
    "def fn():\n",
    "    file_path = r\"D:\\Dota 2\\Heroes\\Pickles\\sized_letter_images.pickle\"\n",
    "    if os.access(file_path, os.F_OK):\n",
    "        with open(file_path, 'rb') as fin:\n",
    "            # Read the dictionary of letter image counts.\n",
    "            d = pickle.load(fin)\n",
    "            # Read each letter's images in lexical order.\n",
    "            for k in sorted(d):\n",
    "                d[k] = pickle.load(fin)\n",
    "    else:\n",
    "        # Create a file that multiple processes can partially load.\n",
    "        d = collections.defaultdict(list)\n",
    "        for file_title, images in data.items():\n",
    "            file_extents = selected_extents[file_title]\n",
    "            letters = [c if file_title in small_letters else c.upper() for c in file_title if c != '_']\n",
    "            for (left, right), letter in zip(file_extents, letters):\n",
    "                for image in images:\n",
    "                    image = cv2.threshold(image, 0, 0, cv2.THRESH_TOZERO | cv2.THRESH_OTSU)[1]\n",
    "                    image = image[:, left:right]\n",
    "                    d[letter].append(image)\n",
    "        with open(file_path, 'wb') as fout:\n",
    "            # Write a dictionary of letter image counts.\n",
    "            pickle.dump({k: len(v) for k, v, in d.items()}, fout)\n",
    "            # Write each letter's images in lexical order.\n",
    "            for k, v in sorted(d.items()):\n",
    "                print(k, len(v))\n",
    "                pickle.dump(tuple(v), fout)\n",
    "    return d\n",
    "sized_letter_images = fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*sorted(sized_letter_images))\n",
    "def fn(fn):\n",
    "    all_letters = {fn(chr(i)) for i in range(ord('A'), ord('Z') + 1)}\n",
    "    given_letters = {c for c in sized_letter_images if c == fn(c)}\n",
    "    missing_letters = all_letters - given_letters\n",
    "    print('missing', len(missing_letters), sorted(missing_letters))\n",
    "fn(str.upper)\n",
    "fn(str.lower)\n",
    "[(k, len(v)) for k, v in sorted(sized_letter_images.items())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display examples of each letter.\n",
    "display_examples(sized_letter_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the minimum number of zeros to include images.\n",
    "class Finder:\n",
    "    def __init__(self, images):\n",
    "        self.__nzeros = [image.sum() for image in images]\n",
    "        self.__len = op.mul(*images[0].shape[:2])\n",
    "        self.__n = len(images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        l = [nzeros for nzeros in self.__nzeros if nzeros >= index]\n",
    "        return 1 if len(l) * 10 < self.__n else -1\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.__len\n",
    "\n",
    "def fn(file_title, file_images):\n",
    "    print(file_title)\n",
    "    file_images = [cv2.threshold(i, 0, 0, cv2.THRESH_TOZERO | cv2.THRESH_OTSU)[1] == 0 for i in file_images]\n",
    "    letters = [c if file_title in small_letters else c.upper() for c in file_title if c != '_']\n",
    "    def fn(t):\n",
    "        index, horizontal_extent = t\n",
    "        left, right = horizontal_extent\n",
    "        #letter_images = [image[4:-3, left:right] for image in file_images]\n",
    "        #minimum_nzero = (file_images[0].shape[0] - 7) * -op.sub(*selected_extents[file_title][1]) // 2\n",
    "        letter_images = [image[:, left:right] for image in file_images]\n",
    "        minimum_nzero = bisect.bisect_left(Finder(letter_images), 0)\n",
    "        return index, minimum_nzero - 1\n",
    "    file_extents = selected_extents[file_title]\n",
    "    d = dict(map(fn, enumerate(file_extents)))\n",
    "    return d\n",
    "#minimum_nzeros = {k: fn(k, v) for k, v in data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the minimum numbers of zeros created above.\n",
    "minimum_nzeros = {\n",
    "    'ancient_apparition': {0: 86, 1: 100, 2: 87, 3: 43, 4: 56, 5: 82, 6: 87, 7: 101, 8: 69, 9: 70, 10: 101, 11: 82, 12: 43, 13: 87, 14: 43, 15: 97, 16: 82},\n",
    "    'anti-mage': {0: 114, 1: 94, 2: 101, 3: 42, 4: 62, 5: 106, 6: 111, 7: 96, 8: 68},\n",
    "    'broodmother': {0: 79, 1: 79, 2: 108, 3: 110, 4: 90, 5: 106, 6: 108, 7: 101, 8: 96, 9: 68, 10: 91},\n",
    "    'centaur_warrunner': {0: 87, 1: 69, 2: 99, 3: 87, 4: 70, 5: 85, 6: 83, 7: 127, 8: 70, 9: 67, 10: 67, 11: 83, 12: 82, 13: 84, 14: 69, 15: 83},\n",
    "    'clinkz': {0: 99, 1: 82, 2: 52, 3: 94, 4: 95, 5: 82},\n",
    "    'io': {0: 42, 1: 108},\n",
    "    'juggernaut': {0: 72, 1: 96, 2: 96, 3: 98, 4: 79, 5: 79, 6: 94, 7: 114, 8: 94, 9: 101},\n",
    "    'keeper_of_the_light': {0: 85, 1: 69, 2: 72, 3: 69, 4: 71, 5: 82, 6: 95, 7: 70, 8: 88, 9: 84, 10: 72, 11: 73, 12: 43, 13: 87, 14: 84, 15: 88},\n",
    "    \"nature's_prophet\": {0: 94, 1: 98, 2: 85, 3: 80, 4: 92, 5: 79, 6: 46, 7: 83, 8: 77, 9: 80, 10: 110, 11: 83, 12: 94, 13: 79, 14: 101},\n",
    "    'nyx_assassin': {0: 93, 1: 100, 2: 95, 3: 97, 4: 84, 5: 84, 6: 111, 7: 81, 8: 81, 9: 52, 10: 94},\n",
    "    'outworld_devourer': {0: 99, 1: 83, 2: 87, 3: 115, 4: 97, 5: 69, 6: 70, 7: 81, 8: 81, 9: 68, 10: 88, 11: 99, 12: 83, 13: 83, 14: 70, 15: 69},\n",
    "    'queen_of_pain': {0: 134, 1: 79, 2: 79, 3: 67, 4: 93, 5: 123, 6: 81, 7: 82, 8: 95, 9: 52, 10: 94},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the images resulting from applying the minimum numbers of zeros.\n",
    "def fn(file_title, index, minimum_nzeros):\n",
    "    g = (image for image in data[file_title])\n",
    "    g = (cv2.threshold(image, 0, 0, cv2.THRESH_TOZERO | cv2.THRESH_OTSU)[1] for image in g)\n",
    "    left, right = selected_extents[file_title][index]\n",
    "    g = (image[:, left:right] for image in g)\n",
    "    g = (image for image in g if minimum_nzeros * 1.1 > (image == 0).sum() >= minimum_nzeros)\n",
    "    g = next(grouper(g, 1200))\n",
    "    image = np.vstack([np.hstack(list(g)) for g in grouper(g, 60)])\n",
    "    #print(file_title, index, minimum_nzeros, [c for c in file_title if c != '_'][index].upper())\n",
    "    return show_and_wait(image)\n",
    "g = ((s, i, m) for s in file_titles for i, m in sorted(minimum_nzeros[s].items()))\n",
    "list(it.takewhile(lambda t: fn(*t) != 'q', g))\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of clean letters to images for each extent extracted from each image in each video file.\n",
    "# Distinguish between large and small letter renderings by using an upper-case letter for the large ones and\n",
    "# a lower-case letter for the small ones.\n",
    "def fn():\n",
    "    file_path = r\"D:\\Dota 2\\Heroes\\Pickles\\clean_letter_images.pickle\"\n",
    "    if os.access(file_path, os.F_OK):\n",
    "        with open(file_path, 'rb') as fin:\n",
    "            # Read the dictionary of letter image counts.\n",
    "            d = pickle.load(fin)\n",
    "            # Read each letter's images in lexical order.\n",
    "            for k in sorted(d):\n",
    "                d[k] = pickle.load(fin)\n",
    "        print({k: len(v) for k, v, in d.items()})\n",
    "    else:\n",
    "        # Create a file that multiple processes can partially load.\n",
    "        d = collections.defaultdict(list)\n",
    "        for file_title, images in data.items():\n",
    "            file_minimum_nzeros = minimum_nzeros[file_title]\n",
    "            l = [cv2.threshold(image, 0, 0, cv2.THRESH_TOZERO | cv2.THRESH_OTSU)[1] for image in images]\n",
    "            file_extents = selected_extents[file_title]\n",
    "            letters = [c if file_title in small_letters else c.upper() for c in file_title if c != '_']\n",
    "            for (left, right), (index, letter) in zip(file_extents, enumerate(letters)):\n",
    "                m = file_minimum_nzeros[index]\n",
    "                for image in l:\n",
    "                    image = image[:, left:right]\n",
    "                    if m * 1.1 > (image == 0).sum() >= m:\n",
    "                        d[letter].append(image)\n",
    "        with open(file_path, 'wb') as fout:\n",
    "            # Write a dictionary of letter image counts.\n",
    "            pickle.dump({k: len(v) for k, v, in d.items()}, fout)\n",
    "            # Write each letter's images in lexical order.\n",
    "            for k, v in sorted(d.items()):\n",
    "                print(k, len(v))\n",
    "                pickle.dump(tuple(v), fout)\n",
    "    return d\n",
    "clean_letter_images = fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect clean letter images.\n",
    "def fn():\n",
    "    for letter, images in clean_letter_images.items():\n",
    "        image = np.vstack([np.hstack(list(g)) for g in grouper(images[:1200], 60)])\n",
    "        print(letter)\n",
    "        if show_and_wait(image) == 'q':\n",
    "            break\n",
    "#fn()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_margin = 5\n",
    "def put_text(background: np.ndarray, text: str, letter_images):\n",
    "    image = background.copy()\n",
    "\n",
    "    # Construct the image of the text.\n",
    "    dtype, height, width = image.dtype, *image.shape\n",
    "    def make_letter(letter):\n",
    "        image = random.choice(letter_images[letter])\n",
    "        return image\n",
    "    def make_space():\n",
    "        # Randomly add to the text about one space for every five characters.\n",
    "        width = random.randint(7, 8) if random.random() < .167 else random.randint(0, 1)\n",
    "        image = np.zeros((height, width), dtype)\n",
    "        return image\n",
    "    def fn():\n",
    "        a = map(make_letter, text)\n",
    "        b = (make_space() for _ in text)\n",
    "        g = it.chain.from_iterable(zip(a, b))\n",
    "        image = np.hstack(list(g)[:-1])\n",
    "        if image.shape[1] < width - 2 * horizontal_margin:\n",
    "            # Select a random position for the rendered text in the background.\n",
    "            left = random.randrange(horizontal_margin, width - horizontal_margin - image.shape[1])\n",
    "            right = width - image.shape[1] - left\n",
    "            return np.hstack([np.zeros((height, left), dtype), image, np.zeros((height, right), dtype)])\n",
    "    text_image = fn()\n",
    "    if text_image is None:\n",
    "        # The text renders too wide.  Try again.\n",
    "        return\n",
    "\n",
    "    # Apply the rendered greyscale text to the background.\n",
    "    image = image * (text_image == 0) + text_image\n",
    "    image = cv2.threshold(image, 0, 0, cv2.THRESH_TOZERO | cv2.THRESH_OTSU)[1]\n",
    "    image = image * (text_image == 0) + text_image\n",
    "\n",
    "    # Add the removed dimension.\n",
    "    image = image[:, :, np.newaxis]\n",
    "\n",
    "    return image\n",
    "image = put_text(np.zeros((16, 120), np.uint8), 'ACDEF', clean_letter_images)\n",
    "show_and_wait(image)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 1200 of each letter.\n",
    "# Manually select ranges of images to exclude.\n",
    "nimages = 1200\n",
    "ncolumns = 60\n",
    "window_name = 'tesst'\n",
    "cv2.namedWindow(window_name, cv2.WINDOW_NORMAL | cv2.WINDOW_GUI_EXPANDED)\n",
    "def fn(file_title, horizontal_extent):\n",
    "    images = data[file_title]\n",
    "    indices = list(range(nimages))\n",
    "    left, right = horizontal_extent\n",
    "    def fn():\n",
    "        g = (cv2.threshold(images[i], 0, 0, cv2.THRESH_TOZERO | cv2.THRESH_OTSU)[1][:, left:right] for i in indices)\n",
    "        g = grouper(g, ncolumns)\n",
    "        return np.vstack([np.hstack(list(g)) for g in g])\n",
    "    initial_index = []\n",
    "    height, width = images[0].shape[0], right - left\n",
    "    def handle_mouse_event(event, x, y, *_):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            initial_index.clear()\n",
    "            initial_index.append((y // height) * ncolumns + x // width)\n",
    "        elif event == cv2.EVENT_RBUTTONDOWN:\n",
    "            index = (y // height) * ncolumns + x // width\n",
    "            begin, end = initial_index[0] if initial_index else index, index + 1\n",
    "            del indices[begin:end]\n",
    "            begin = indices[-1] + 1\n",
    "            end = begin + nimages - len(indices)\n",
    "            indices.extend(range(begin, end))\n",
    "            cv2.imshow(window_name, fn())\n",
    "            initial_index.clear()\n",
    "    cv2.setMouseCallback(window_name, handle_mouse_event)\n",
    "    show_and_wait(fn())\n",
    "    return indices\n",
    "#fn('io', selected_extents['io'][1])\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 1200 of each letter.\n",
    "# Manually select the minimum number of zeros to include images.\n",
    "nimages = 1200\n",
    "ncolumns = 60\n",
    "window_name = 'tesst'\n",
    "cv2.namedWindow(window_name, cv2.WINDOW_NORMAL | cv2.WINDOW_GUI_EXPANDED)\n",
    "def fn(file_title, horizontal_extent):\n",
    "    images = data[file_title]\n",
    "    minimum_nzero = images[0].shape[0] * -op.sub(*selected_extents[file_title][1]) // 2\n",
    "    left, right = horizontal_extent\n",
    "    def fn():\n",
    "        l = random.sample(images, len(images))\n",
    "        g = (cv2.threshold(image, 0, 0, cv2.THRESH_TOZERO | cv2.THRESH_OTSU)[1] for image in l)\n",
    "        g = (image[:, left:right] for image in g)\n",
    "        return [image for image in g if (image == 0).sum() >= minimum_nzero]\n",
    "    while True:\n",
    "        l = fn()\n",
    "        if len(l) < nimages:\n",
    "            image = np.zeros([1, 1], dtype=images[0].dtype)\n",
    "        else:\n",
    "            image = np.vstack([np.hstack(list(g)) for g in grouper(l[:nimages], ncolumns)])\n",
    "        ch = show_and_wait(image)\n",
    "        if ch == '-':\n",
    "            minimum_nzero -= 1\n",
    "        elif ch == '+':\n",
    "            minimum_nzero += 1\n",
    "        elif ch == '/':\n",
    "            minimum_nzero -= 10\n",
    "        elif ch == '*':\n",
    "            minimum_nzero += 10\n",
    "        elif ch == 'p':\n",
    "            print(minimum_nzero, len(l))\n",
    "        elif ch == 'q':\n",
    "            return minimum_nzero, len(fn())\n",
    "#print(fn('io', selected_extents['io'][1]))\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
